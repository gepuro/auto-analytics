# Auto Analytics AI Agent - é–‹ç™ºæ‰‹é †æ›¸ï¼ˆdevcontainerç’°å¢ƒï¼‰

## 1. é–‹ç™ºæ¦‚è¦

### 1.1 é–‹ç™ºç’°å¢ƒå‰æ
- **VS Code devcontainer**: .devcontainer/docker-compose.yml ã§ PostgreSQL èµ·å‹•æ¸ˆã¿
- **çµ±ä¸€é–‹ç™ºç’°å¢ƒ**: ãƒãƒ¼ãƒ å…¨ä½“ã§åŒä¸€ã®é–‹ç™ºç’°å¢ƒã‚’å…±æœ‰
- **ã‚³ãƒ³ãƒ†ãƒŠåˆ†é›¢**: ãƒ›ã‚¹ãƒˆç’°å¢ƒã«å½±éŸ¿ã—ãªã„ç‹¬ç«‹ã—ãŸé–‹ç™ºç’°å¢ƒ

### 1.2 é–‹ç™ºæ–¹é‡
- **æ®µéšçš„å®Ÿè£…**: å°ã•ãªå˜ä½ã§æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§å‹•ä½œç¢ºèª
- **uvç’°å¢ƒæ´»ç”¨**: uvã«ã‚ˆã‚‹é«˜é€Ÿãªä¾å­˜é–¢ä¿‚ç®¡ç†ã¨ä»®æƒ³ç’°å¢ƒ
- **ADK Web UIæ´»ç”¨**: `uv run adk web`ã‚³ãƒãƒ³ãƒ‰ã«ã‚ˆã‚‹é–‹ç™ºç”¨UIã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ä½œç¢ºèª
- **ç¶™ç¶šçš„æ¤œè¨¼**: å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå®Ÿè£…å¾Œã«å³åº§ã«çµ±åˆãƒ†ã‚¹ãƒˆ
- **ã‚¨ãƒ©ãƒ¼é§†å‹•é–‹ç™º**: å•é¡Œã‚’æ—©æœŸç™ºè¦‹ã—ã€ä¿®æ­£ã‚µã‚¤ã‚¯ãƒ«ã‚’çŸ­ç¸®

### 1.3 uvç’°å¢ƒã®åˆ©ç‚¹
- **é«˜é€Ÿã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**: pipã‚ˆã‚Šã‚‚10-100å€é«˜é€Ÿãªä¾å­˜é–¢ä¿‚è§£æ±º
- **ç¢ºå®Ÿãªå†ç¾æ€§**: uv.lockã«ã‚ˆã‚‹å®Œå…¨ãªç’°å¢ƒå†ç¾
- **çµ±ä¸€ç®¡ç†**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ä¾å­˜é–¢ä¿‚ã€ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã®ä¸€å…ƒç®¡ç†
- **Pythonç‰ˆç®¡ç†**: è¤‡æ•°Pythonç‰ˆã®è‡ªå‹•ç®¡ç†

### 1.4 æ¤œè¨¼ç’°å¢ƒï¼ˆdevcontainerå†…ï¼‰
- **é–‹ç™ºç’°å¢ƒ**: VS Code devcontainer
- **é–‹ç™ºUI**: ADK Web UI (`http://localhost:8080`)
- **MCP Server**: genai-toolbox (`http://localhost:5000`)
- **PostgreSQL**: devcontainer docker-compose (`localhost:5432`)
- **ãƒ­ã‚°ç›£è¦–**: æ§‹é€ åŒ–ãƒ­ã‚°ã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–

## 2. ADKæœ€å°æ§‹æˆï¼ˆç¾åœ¨ã®å®Ÿè£…çŠ¶æ…‹ï¼‰

### 2.1 å®Ÿè£…æ¸ˆã¿ADKæœ€å°æ§‹æˆ
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¯Google ADKã®ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã«åŸºã¥ãæœ€å°æ§‹æˆãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚

**src/main.py - ADKæœ€å°æ§‹æˆ**:
```python
"""
Google ADK Quickstart - Multi-Tool Agent
Following the quickstart guide at https://google.github.io/adk-docs/get-started/quickstart/
"""

import os
import asyncio
import datetime
from zoneinfo import ZoneInfo
from google.adk.agents import Agent
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
from google.genai import types

# 2ã¤ã®ãƒ„ãƒ¼ãƒ«é–¢æ•°
def get_weather(city: str) -> dict:
    """å¤©æ°—æƒ…å ±å–å¾—ï¼ˆNew Yorkã®ã¿å¯¾å¿œï¼‰"""
    
def get_current_time(city: str) -> dict:
    """ç¾åœ¨æ™‚åˆ»å–å¾—ï¼ˆè¤‡æ•°éƒ½å¸‚å¯¾å¿œï¼‰"""

# ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
root_agent = Agent(
    name="weather_time_agent",
    model="gemini-2.0-flash",
    description="å¤©æ°—ã¨æ™‚åˆ»ã®ä¸¡æ–¹ã«å¯¾å¿œ",
    tools=[get_weather, get_current_time]
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã¨ãƒ©ãƒ³ãƒŠãƒ¼
async def main():
    session_service = InMemorySessionService()
    runner = Runner(agent=root_agent, ...)
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ«ãƒ¼ãƒ—
```

**å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½**:
- âœ… `get_weather()`: å¤©æ°—æƒ…å ±å–å¾—ãƒ„ãƒ¼ãƒ«
- âœ… `get_current_time()`: ç¾åœ¨æ™‚åˆ»å–å¾—ãƒ„ãƒ¼ãƒ«  
- âœ… ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«ADKã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- âœ… InMemorySessionService
- âœ… Runnerè¨­å®š
- âœ… ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

**å¯¾å¿œéƒ½å¸‚**:
- å¤©æ°—: New Yorkï¼ˆã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆä»•æ§˜ï¼‰
- æ™‚åˆ»: New York, Tokyo, London, Paris, Sydney

**ä½¿ç”¨æ–¹æ³•**:
```bash
# ADKæœ€å°æ§‹æˆå®Ÿè¡Œ
python src/main.py

# ä½¿ç”¨ä¾‹
"What's the weather in New York?"
"What time is it in Tokyo?"
```

### 2.2 ADKæœ€å°æ§‹æˆã®ç‰¹å¾´
- **Google ADKã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆæº–æ‹ **: å…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«å®Œå…¨æº–æ‹ 
- **ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«å¯¾å¿œ**: 1ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§è¤‡æ•°ã®æ©Ÿèƒ½æä¾›
- **Gemini 2.0 Flash**: æœ€æ–°ã®Geminiãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
- **å‹å®‰å…¨**: Pythonå‹ãƒ’ãƒ³ãƒˆå®Œå‚™
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: é©åˆ‡ãªä¾‹å¤–å‡¦ç†
- **æ‹¡å¼µå¯èƒ½**: è¿½åŠ ãƒ„ãƒ¼ãƒ«ã®å®¹æ˜“ãªå®Ÿè£…

### 2.3 ADKæœ€å°æ§‹æˆã®æŠ€è¡“ä»•æ§˜

**ä¾å­˜é–¢ä¿‚ (pyproject.toml)**:
```toml
dependencies = [
    "google-adk>=1.4.1",
    "google-generativeai>=0.8.5",
    # ãã®ä»–ã®ä¾å­˜é–¢ä¿‚
]
```

**ãƒ„ãƒ¼ãƒ«é–¢æ•°ã®å®Ÿè£…**:
- `get_weather(city: str) -> dict`: æŒ‡å®šéƒ½å¸‚ã®å¤©æ°—æƒ…å ±å–å¾—
  - New Yorkå¯¾å¿œï¼ˆã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆä»•æ§˜æº–æ‹ ï¼‰
  - æˆåŠŸæ™‚: `{"status": "success", "report": "å¤©æ°—æƒ…å ±"}`
  - ã‚¨ãƒ©ãƒ¼æ™‚: `{"status": "error", "error_message": "ã‚¨ãƒ©ãƒ¼å†…å®¹"}`

- `get_current_time(city: str) -> dict`: æŒ‡å®šéƒ½å¸‚ã®ç¾åœ¨æ™‚åˆ»å–å¾—
  - è¤‡æ•°éƒ½å¸‚å¯¾å¿œï¼ˆNew York, Tokyo, London, Paris, Sydneyï¼‰
  - timezoneæƒ…å ±ã‚’ä½¿ç”¨ã—ãŸæ­£ç¢ºãªæ™‚åˆ»è¨ˆç®—
  - ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: "YYYY-MM-DD HH:MM:SS TZ+offset"

**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š**:
```python
Agent(
    name="weather_time_agent",
    model="gemini-2.0-flash",
    description="Agent to answer questions about the time and weather in a city.",
    instruction="You are a helpful agent who can answer user questions about the time and weather in a city...",
    tools=[get_weather, get_current_time]
)
```

**ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†**:
- `InMemorySessionService`: ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: "demo_user"
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: "demo_session"
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å: "weather_time_demo"

**å®Ÿè¡Œç’°å¢ƒ**:
- Python 3.11+
- éåŒæœŸå‡¦ç†å¯¾å¿œ (asyncio)
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚³ãƒ³ã‚½ãƒ¼ãƒ«UI
- 'quit'/'exit'ã‚³ãƒãƒ³ãƒ‰ã§çµ‚äº†

### 2.4 ADKæœ€å°æ§‹æˆã®å‹•ä½œç¢ºèª
```bash
# 1. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
uv sync

# 2. Google APIã‚­ãƒ¼è¨­å®šç¢ºèª
echo $GOOGLE_API_KEY

# 3. ADKæœ€å°æ§‹æˆå®Ÿè¡Œ
python src/main.py

# 4. ãƒ†ã‚¹ãƒˆç”¨ã‚¯ã‚¨ãƒªä¾‹
"What's the weather in New York?"
"What time is it in Tokyo?"
"Tell me the current time in London"
"How's the weather in New York?"
```

**æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ**:
1. ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆæˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
2. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º
3. ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ­ã‚°è¡¨ç¤ºï¼ˆ"--- Tool: XXX called for city: YYY ---"ï¼‰
4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®é©åˆ‡ãªå¿œç­”
5. ã‚¨ãƒ©ãƒ¼æ™‚ã®é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

### 2.5 ç¾åœ¨ã®å®Ÿè£…çŠ¶æ³ã¾ã¨ã‚

**âœ… å®Œäº†æ¸ˆã¿ï¼ˆADKæœ€å°æ§‹æˆï¼‰**:
- Google ADK Quickstartå®Œå…¨å®Ÿè£…
- ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆå¤©æ°—ï¼‹æ™‚åˆ»ï¼‰
- InMemorySessionServiceå®Ÿè£…
- Runnerè¨­å®š
- éåŒæœŸå‡¦ç†å¯¾å¿œ
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚³ãƒ³ã‚½ãƒ¼ãƒ«UI
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- è¤‡æ•°ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å¯¾å¿œ

**ğŸ“‹ ç¾åœ¨ã®é–‹ç™ºçŠ¶æ…‹**:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹: ADKæœ€å°æ§‹æˆã¨ã—ã¦å‹•ä½œä¸­
- æ‹¡å¼µã®æº–å‚™å®Œäº†: ã“ã®åŸºç›¤ã®ä¸Šã«è¿½åŠ æ©Ÿèƒ½ã‚’å®Ÿè£…å¯èƒ½
- å“è³ªä¿è¨¼: Googleå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«æº–æ‹ ã§ä¿¡é ¼æ€§ç¢ºä¿

**ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆæ—¢å­˜ã®é–‹ç™ºæ‰‹é †æ›¸ã«å¾“ã£ã¦ï¼‰**:
1. **Phase 1**: devcontainerç’°å¢ƒã§ã®å„ç¨®ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ç¢ºèª
2. **Phase 2**: MCPçµ±åˆã¨SQLåŸºç›¤å®Ÿè£…
3. **Phase 3**: Geminiæ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè£…
4. **Phase 4**: ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
5. **Phase 5**: SQLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
6. **Phase 6**: åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
7. **Phase 7**: çµ±åˆãƒ†ã‚¹ãƒˆãƒ»å®Œæˆ

**ğŸ’¡ é–‹ç™ºæ–¹é‡**:
- ç¾åœ¨ã®ADKæœ€å°æ§‹æˆã‚’åŸºç›¤ã¨ã—ã¦ç¶­æŒ
- æ®µéšçš„ã«æ©Ÿèƒ½ã‚’è¿½åŠ å®Ÿè£…
- å„ãƒ•ã‚§ãƒ¼ã‚ºã§å‹•ä½œç¢ºèªã‚’å®Ÿæ–½
- æ—¢å­˜ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆï¼ˆsrc/agents/ï¼‰ã¨çµ±åˆ

## 3. Phase 1: ç’°å¢ƒæ§‹ç¯‰ã¨Hello Worldï¼ˆ1-2æ—¥ï¼‰

### Step 1.1: devcontainerç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# 1. devcontainerå†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
echo "Devcontainerç’°å¢ƒ: $REMOTE_CONTAINERS"
whoami  # vscode ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

# 2. uvã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèªï¼ˆdevcontainerã«å«ã¾ã‚Œã¦ã„ã‚‹å‰æï¼‰
uv --version  # uvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª

# 3. Pythonç’°å¢ƒç¢ºèª
uv python list  # åˆ©ç”¨å¯èƒ½ãªPythonç‰ˆç¢ºèª
python --version  # ç¾åœ¨ã®Pythonç‰ˆç¢ºèª

# 4. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾å­˜é–¢ä¿‚åŒæœŸ
cd /workspace  # devcontainerå†…ã®ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹
uv sync  # pyproject.tomlã¨uv.lockã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’åŒæœŸ

# 5. ç’°å¢ƒå¤‰æ•°è¨­å®š
cp .env.example .env 2>/dev/null || echo "# Auto Analytics ç’°å¢ƒå¤‰æ•°" > .env
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
```

**å‹•ä½œç¢ºèª**:
```bash
# uvç’°å¢ƒå†…ã§ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª
uv run python -c "import sys; print(f'Python: {sys.version}')"
uv run python -c "import google.generativeai as genai; print('Gemini API ready')" || echo "Geminiæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¾Œã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰"
uv run python -c "import google.adk; print('ADK ready')" || echo "ADKæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¾Œã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰"

# ä¾å­˜é–¢ä¿‚è¡¨ç¤º
uv tree

# devcontainerå†…Dockerç¢ºèª
docker --version
docker-compose --version
```

### Step 1.2: PostgreSQLç’°å¢ƒç¢ºèªï¼ˆ.devcontainer/docker-compose.ymlä½¿ç”¨ï¼‰

**devcontainer PostgreSQLç¢ºèª**:
```bash
# devcontainerèµ·å‹•æ™‚ã«PostgreSQLãŒæ—¢ã«èµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
echo "ğŸ” PostgreSQLèµ·å‹•çŠ¶æ…‹ç¢ºèª..."

# .devcontainer/docker-compose.ymlç¢ºèª
ls -la /workspace/.devcontainer/docker-compose.yml || echo "âŒ .devcontainer/docker-compose.yml ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

# PostgreSQLæ¥ç¶šç¢ºèª
echo "ğŸ“¡ PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆ..."
PGPASSWORD=password psql -h localhost -U postgres -d postgres -c "SELECT version();" || echo "âš ï¸  PostgreSQLæ¥ç¶šç¢ºèªä¸­..."

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª/ä½œæˆ
echo "ğŸ”§ Analyticsç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª..."
```

**Analyticsç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–**:
```sql
-- devcontainer PostgreSQLã§Analyticsç’°å¢ƒæ§‹ç¯‰
-- æ—¢å­˜ã®PostgreSQLã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«Analyticsç”¨è¨­å®šã‚’è¿½åŠ 

-- Analyticsç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
CREATE DATABASE analytics;

-- Analyticsç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
CREATE USER analytics_user WITH PASSWORD 'secure_password';

-- æ¨©é™è¨­å®š
GRANT ALL PRIVILEGES ON DATABASE analytics TO analytics_user;

-- analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã—ã¦ä½œæ¥­
\c analytics;

-- ã‚¹ã‚­ãƒ¼ãƒæ¨©é™è¨­å®š
GRANT ALL PRIVILEGES ON SCHEMA public TO analytics_user;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO analytics_user;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO analytics_user;
```

**ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ**:
```bash
# devcontainerå†…ã§Analyticsãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
cat > /workspace/init_analytics.sql << 'EOF'
-- Analyticsç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
CREATE DATABASE IF NOT EXISTS analytics;

\c analytics;

-- Analyticsç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆï¼ˆæ—¢å­˜ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
DO $$
BEGIN
    IF NOT EXISTS (SELECT FROM pg_roles WHERE rolname = 'analytics_user') THEN
        CREATE USER analytics_user WITH PASSWORD 'secure_password';
    END IF;
END
$$;

-- æ¨©é™è¨­å®š
GRANT ALL PRIVILEGES ON DATABASE analytics TO analytics_user;
GRANT ALL PRIVILEGES ON SCHEMA public TO analytics_user;

-- usersãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
DROP TABLE IF EXISTS users;
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    age INTEGER CHECK (age >= 0 AND age <= 150),
    email VARCHAR(200) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
INSERT INTO users (name, age, email) VALUES
('å¤ªéƒ', 25, 'taro@example.com'),
('èŠ±å­', 30, 'hanako@example.com'),
('æ¬¡éƒ', 35, 'jiro@example.com'),
('å››éƒ', 28, 'shiro@example.com'),
('äº”éƒ', 42, 'goro@example.com'),
('å…­å­', 33, 'rokuko@example.com'),
('ä¸ƒç¾', 27, 'nanami@example.com'),
('å…«éƒ', 38, 'hachiro@example.com'),
('ä¹å·', 45, 'kyushu@example.com'),
('åå­', 29, 'toko@example.com');

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
CREATE INDEX idx_users_age ON users(age);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at);

-- Analyticsç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ¨©é™ä»˜ä¸
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO analytics_user;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO analytics_user;

-- çµ±è¨ˆæƒ…å ±æ›´æ–°
ANALYZE users;

SELECT 'Analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†' as status;
EOF

# PostgreSQLåˆæœŸåŒ–å®Ÿè¡Œ
echo "ğŸš€ Analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ä¸­..."
PGPASSWORD=password psql -h localhost -U postgres -f /workspace/init_analytics.sql

echo "âœ… Analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†"
```

**PostgreSQLæ¥ç¶šç¢ºèª**:
```bash
# Analyticsç”¨æ¥ç¶šç¢ºèª
echo "ğŸ“Š Analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª..."
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics -c "
SELECT 
    'Analytics PostgreSQLæ¥ç¶šæˆåŠŸ' as status,
    version() as postgres_version,
    current_database() as database_name,
    current_user as user_name;
"

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª
echo "ğŸ“ˆ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª..."
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics -c "
SELECT 
    COUNT(*) as total_users,
    ROUND(AVG(age), 2) as avg_age,
    MIN(age) as min_age,
    MAX(age) as max_age
FROM users;
"

# å¹´é½¢åˆ†å¸ƒç¢ºèª
echo "ğŸ“Š å¹´é½¢åˆ†å¸ƒç¢ºèª..."
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics -c "
SELECT 
    CASE 
        WHEN age < 30 THEN '20ä»£'
        WHEN age < 40 THEN '30ä»£' 
        ELSE '40ä»£ä»¥ä¸Š'
    END as age_group,
    COUNT(*) as count,
    ROUND(AVG(age), 1) as avg_age_in_group
FROM users 
GROUP BY age_group 
ORDER BY age_group;
"
```

**.envè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆdevcontainerç”¨ï¼‰**:
```bash
# devcontainerå†…ã§.envè¨­å®š
cat > /workspace/.env << 'EOF'
# Auto Analytics ç’°å¢ƒå¤‰æ•°ï¼ˆdevcontainerç’°å¢ƒï¼‰

# PostgreSQLè¨­å®šï¼ˆ.devcontainer/docker-compose.ymlèµ·å‹•æ¸ˆã¿ï¼‰
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=analytics
POSTGRES_USER=analytics_user
POSTGRES_PASSWORD=secure_password
POSTGRES_URL=postgresql://analytics_user:secure_password@localhost:5432/analytics

# devcontainer PostgreSQLç®¡ç†è€…è¨­å®š
POSTGRES_ADMIN_USER=postgres
POSTGRES_ADMIN_PASSWORD=password

# Google AIè¨­å®šï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰
GOOGLE_API_KEY=your_actual_gemini_api_key_here
GOOGLE_CLOUD_PROJECT=your_project_id

# MCP Serverè¨­å®š
TOOLBOX_SERVER_URL=http://localhost:5000
TOOLBOX_CONFIG_PATH=/workspace/config/tools.yaml

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
LOG_LEVEL=INFO
MAX_CONVERSATION_HISTORY=50
QUERY_TIMEOUT=300

# devcontainerç’°å¢ƒè­˜åˆ¥
ENVIRONMENT=devcontainer
DEVCONTAINER_NAME=auto-analytics
EOF

echo "âœ… .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ"
echo "ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
echo "  1. GOOGLE_API_KEY ã‚’å®Ÿéš›ã®Gemini APIã‚­ãƒ¼ã«è¨­å®šã—ã¦ãã ã•ã„"
echo "  2. å¿…è¦ã«å¿œã˜ã¦GOOGLE_CLOUD_PROJECT ã‚’è¨­å®šã—ã¦ãã ã•ã„"
echo ""
echo "ğŸ’¡ è¨­å®šç¢ºèª:"
echo "   cat /workspace/.env"
```

### Step 1.3: genai-toolbox MCP Serveræ§‹ç¯‰ï¼ˆdevcontainerå†…ï¼‰
```bash
# 1. devcontainerå†…ã§genai-toolbox ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
cd /workspace
uv add genai-toolbox toolbox-core

# 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p /workspace/config

# 3. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
uv run toolbox --help || echo "toolboxã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
```

**config/tools.yamlä½œæˆ**:
```yaml
sources:
  analytics-postgres:
    kind: postgres
    host: localhost
    port: 5432
    database: analytics
    user: analytics_user
    password: secure_password

tools:
  test-connection:
    kind: postgres-sql
    source: analytics-postgres
    description: "PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆ"
    statement: SELECT 'Hello from PostgreSQL' as message, NOW() as timestamp

toolsets:
  test-toolset:
    tools:
      - test-connection
```

**MCP Serverèµ·å‹•ã¨ç¢ºèªï¼ˆdevcontainerå†…ï¼‰**:
```bash
# devcontainerå†…ã§MCP Serverèµ·å‹•
cd /workspace
uv run toolbox --tools-file config/tools.yaml --port 5000 &

# èµ·å‹•å¾…æ©Ÿ
sleep 3

# æ¥ç¶šç¢ºèª
curl http://localhost:5000/health || echo "MCP Serverèµ·å‹•ä¸­..."

# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep toolbox

# MCP SSEã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¢ºèª
curl -s http://localhost:5000/mcp/sse | head -5 || echo "MCP SSEã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¢ºèªä¸­..."

echo "âœ… MCP Serverèµ·å‹•å®Œäº†ã€‚ãƒãƒ¼ãƒˆ5000ã§ç¨¼åƒä¸­ã§ã™ã€‚"
```

### Step 1.4: æœ€åˆã®ADKã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆï¼ˆdevcontainerå†…ï¼‰

**å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¿½åŠ **:
```bash
# devcontainerå†…ã§ADKé–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
cd /workspace
uv add google-adk google-generativeai
```

**src/main.pyä½œæˆ**:
```python
from google.adk.agents import Agent
from google.adk.runners import ConsoleRunner
import os
from dotenv import load_dotenv

# devcontainerå†…ã§ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv("/workspace/.env")

# Gemini APIã‚­ãƒ¼ç¢ºèª
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key or api_key == "your_actual_gemini_api_key_here":
    print("âŒ GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    exit(1)

# Hello Worldã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
hello_agent = Agent(
    name="hello_assistant",
    model="gemini-2.0-flash-exp",
    instruction="ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚devcontainerç’°å¢ƒã§å‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’èªè­˜ã—ã¦ãã ã•ã„ã€‚",
    description="Auto Analytics Hello World Agent (devcontainer)"
)

if __name__ == "__main__":
    print("ğŸš€ Auto Analytics Hello World Agent èµ·å‹•ä¸­...")
    print(f"ğŸ“ ç’°å¢ƒ: {os.getenv('ENVIRONMENT', 'unknown')}")
    print("ğŸ’¬ 'exit' ã¾ãŸã¯ 'quit' ã§çµ‚äº†ã—ã¾ã™")
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§å‹•ä½œç¢ºèª
    try:
        runner = ConsoleRunner(hello_agent)
        runner.run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Hello World Agent ã‚’çµ‚äº†ã—ã¾ã™")
```

**å‹•ä½œç¢ºèªï¼ˆdevcontainerå†…ï¼‰**:
```bash
# src ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p /workspace/src

# ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ï¼‰
cd /workspace
uv run python src/main.py
# "ã“ã‚“ã«ã¡ã¯"ã¨å…¥åŠ›ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
# "devcontainerç’°å¢ƒã«ã¤ã„ã¦æ•™ãˆã¦"ãªã©å…¥åŠ›ã—ã¦ãƒ†ã‚¹ãƒˆ

# ADK Web UIèµ·å‹•ï¼ˆdevcontainerå†…ï¼‰
uv run adk web --host 0.0.0.0 --port 8080
# VS Codeã®ãƒãƒ¼ãƒˆè»¢é€ã§ http://localhost:8080 ã‚’é–‹ã
# ã¾ãŸã¯ã€ãƒãƒ¼ãƒˆè»¢é€ã‚¿ãƒ–ã§8080ç•ªãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯
# Hello Worldã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å¯¾è©±ã‚’ç¢ºèª
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ Step 1**:
- [ ] devcontainerç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç¢ºèª
- [ ] .devcontainer/docker-compose.yml PostgreSQLèµ·å‹•ç¢ºèª
- [ ] Analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ç¢ºèª
- [ ] PostgreSQL ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª
- [ ] .env è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ»GOOGLE_API_KEYè¨­å®š
- [ ] genai-toolbox MCP Serverèµ·å‹•ç¢ºèª
- [ ] Gemini APIæ¥ç¶šç¢ºèª
- [ ] ADK Web UIå‹•ä½œç¢ºèªï¼ˆãƒãƒ¼ãƒˆè»¢é€ï¼‰
- [ ] Hello Worldã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª

## 3. Phase 2: MCPçµ±åˆã¨SQLåŸºç›¤ï¼ˆ2-3æ—¥ï¼‰

### Step 2.1: MCPçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
**src/agents/mcp_test_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
from toolbox_core import ToolboxClient
import asyncio
import os

class MCPTestAgent:
    def __init__(self):
        self.toolbox_url = os.getenv("TOOLBOX_SERVER_URL", "http://localhost:5000")
        self.agent = None
        
    async def initialize(self):
        # ToolboxClientã§MCPãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
        toolbox_client = ToolboxClient(self.toolbox_url)
        tools = await toolbox_client.load_toolset("test-toolset")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        self.agent = Agent(
            name="mcp_test_agent",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            PostgreSQLã«æ¥ç¶šã—ã¦ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚
            """,
            tools=tools
        )
        
    async def test_connection(self):
        if not self.agent:
            await self.initialize()
        
        # MCPçµŒç”±ã§PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆ
        result = await self.agent.run("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„")
        return result

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°
async def test_mcp_integration():
    agent = MCPTestAgent()
    result = await agent.test_connection()
    print(f"MCP Test Result: {result}")

if __name__ == "__main__":
    asyncio.run(test_mcp_integration())
```

**å‹•ä½œç¢ºèª**:
```bash
# MCPçµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run python src/agents/mcp_test_agent.py

# ADK Web UIã§ãƒ†ã‚¹ãƒˆ
uv run adk web
# MCP Test Agentã§PostgreSQLæ¥ç¶šç¢ºèª
```

### Step 2.2: SQLå®Ÿè¡Œæ©Ÿèƒ½ã®å®Ÿè£…
**config/tools.yamlã«SQLå®Ÿè¡Œãƒ„ãƒ¼ãƒ«è¿½åŠ **:
```yaml
sources:
  analytics-postgres:
    kind: postgres
    host: localhost
    port: 5432
    database: analytics
    user: analytics_user
    password: secure_password

tools:
  test-connection:
    kind: postgres-sql
    source: analytics-postgres
    description: "PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆ"
    statement: SELECT 'Hello from PostgreSQL' as message, NOW() as timestamp

  execute-simple-query:
    kind: postgres-execute-sql
    source: analytics-postgres
    description: "å‹•çš„SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹"

  get-user-list:
    kind: postgres-sql
    source: analytics-postgres
    description: "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’å–å¾—ã™ã‚‹"
    statement: SELECT id, name, age, email FROM users ORDER BY id

  get-table-schema:
    kind: postgres-sql
    source: analytics-postgres
    description: "ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã™ã‚‹"
    statement: |
      SELECT column_name, data_type, is_nullable
      FROM information_schema.columns 
      WHERE table_name = $1
      ORDER BY ordinal_position
    parameters:
      - name: table_name
        type: string
        description: "ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«å"

toolsets:
  sql-toolset:
    tools:
      - test-connection
      - execute-simple-query
      - get-user-list
      - get-table-schema
```

**src/agents/sql_test_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
from toolbox_core import ToolboxClient
import asyncio
import os

class SQLTestAgent:
    def __init__(self):
        self.toolbox_url = os.getenv("TOOLBOX_SERVER_URL", "http://localhost:5000")
        self.agent = None
        
    async def initialize(self):
        toolbox_client = ToolboxClient(self.toolbox_url)
        tools = await toolbox_client.load_toolset("sql-toolset")
        
        self.agent = Agent(
            name="sql_test_agent",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯SQLå®Ÿè¡Œãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã§ãã¾ã™ï¼š
            1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
            2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§å–å¾—
            3. ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒå–å¾—
            4. å‹•çš„SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«å¿œã˜ã¦é©åˆ‡ãªSQLãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
            """,
            tools=tools
        )
        
    async def run_query(self, user_input: str):
        if not self.agent:
            await self.initialize()
        
        result = await self.agent.run(user_input)
        return result

# ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
async def test_sql_functions():
    agent = SQLTestAgent()
    
    test_cases = [
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„",
        "usersãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’æ•™ãˆã¦ãã ã•ã„",
        "å¹´é½¢ãŒ30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œç´¢ã—ã¦ãã ã•ã„"
    ]
    
    for test_case in test_cases:
        print(f"\n=== ãƒ†ã‚¹ãƒˆ: {test_case} ===")
        result = await agent.run_query(test_case)
        print(f"çµæœ: {result}")

if __name__ == "__main__":
    asyncio.run(test_sql_functions())
```

**å‹•ä½œç¢ºèª**:
```bash
# MCP Serverå†èµ·å‹•ï¼ˆæ–°è¨­å®šåæ˜ ï¼‰
pkill -f toolbox
uv run toolbox --tools-file config/tools.yaml --port 5000 &

# SQLæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
uv run python src/agents/sql_test_agent.py

# ADK Web UIã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ†ã‚¹ãƒˆ
uv run adk web
# SQL Test Agentã§å„ç¨®ã‚¯ã‚¨ãƒªå®Ÿè¡Œç¢ºèª
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ Step 2**:
- [ ] MCP ToolboxClientçµ±åˆç¢ºèª
- [ ] PostgreSQLæ¥ç¶šãƒ„ãƒ¼ãƒ«å‹•ä½œç¢ºèª
- [ ] å‹•çš„SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œç¢ºèª
- [ ] ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒå–å¾—ç¢ºèª
- [ ] ADK Web UIã§ã®SQLå®Ÿè¡Œç¢ºèª

## 4. Phase 3: Geminiæ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè£…ï¼ˆ2-3æ—¥ï¼‰

### Step 3.1: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
**src/utils/prompt_templates.pyä½œæˆ**:
```python
"""
æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
"""

INTENT_ANALYSIS_PROMPT = """
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š

{
  "intent": "data_analysis | visualization | report_generation | schema_inquiry | unknown",
  "confidence": "high | medium | low",
  "entities": {
    "tables": ["ãƒ†ãƒ¼ãƒ–ãƒ«åã®ãƒªã‚¹ãƒˆ"],
    "columns": ["ã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆ"],
    "filters": ["ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶"],
    "aggregations": ["é›†è¨ˆæ–¹æ³•"]
  },
  "clarification_needed": false,
  "suggested_actions": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
  "natural_language_sql": "è‡ªç„¶è¨€èªã§ã®SQLèª¬æ˜"
}

åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±:
{available_tables}

ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: {user_input}
"""

SQL_GENERATION_PROMPT = """
ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€PostgreSQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: {user_request}
æ„å›³åˆ†æçµæœ: {intent_analysis}
ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒ: {table_schemas}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{
  "sql": "SELECTæ–‡ã®SQLã‚¯ã‚¨ãƒª",
  "explanation": "ã‚¯ã‚¨ãƒªã®æ—¥æœ¬èªèª¬æ˜",
  "assumptions": ["å‰ææ¡ä»¶ã®ãƒªã‚¹ãƒˆ"],
  "estimated_rows": "äºˆæƒ³ã•ã‚Œã‚‹çµæœè¡Œæ•°"
}

æ³¨æ„äº‹é …:
- SELECTæ–‡ã®ã¿ç”Ÿæˆã—ã¦ãã ã•ã„
- å±é™ºãªã‚¯ã‚¨ãƒªï¼ˆDELETEã€DROPç­‰ï¼‰ã¯ç”Ÿæˆã—ãªã„ã§ãã ã•ã„
- PostgreSQLæ§‹æ–‡ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
"""

def format_intent_analysis_prompt(user_input: str, available_tables: list) -> str:
    """æ„å›³åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    tables_info = "\n".join([f"- {table}" for table in available_tables])
    return INTENT_ANALYSIS_PROMPT.format(
        user_input=user_input,
        available_tables=tables_info
    )

def format_sql_generation_prompt(user_request: str, intent_analysis: dict, table_schemas: dict) -> str:
    """SQLç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    return SQL_GENERATION_PROMPT.format(
        user_request=user_request,
        intent_analysis=intent_analysis,
        table_schemas=table_schemas
    )
```

### Step 3.2: Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…
**src/utils/gemini_client.pyä½œæˆ**:
```python
import google.generativeai as genai
import json
import os
from typing import Dict, Any
import asyncio

class GeminiClient:
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError("Google API key is required")
        
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
    
    async def generate_structured_response(self, prompt: str) -> Dict[str, Any]:
        """æ§‹é€ åŒ–ã•ã‚ŒãŸJSONå¿œç­”ã‚’ç”Ÿæˆ"""
        try:
            response = await asyncio.to_thread(
                self.model.generate_content, 
                prompt
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONæŠ½å‡º
            response_text = response.text.strip()
            
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã®æŠ½å‡ºï¼ˆ```json ... ```ã®å ´åˆï¼‰
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                json_text = response_text[start:end].strip()
            elif response_text.startswith("{"):
                json_text = response_text
            else:
                # JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return {"error": "Invalid JSON response", "raw_response": response_text}
            
            return json.loads(json_text)
            
        except json.JSONDecodeError as e:
            return {"error": f"JSON decode error: {str(e)}", "raw_response": response_text}
        except Exception as e:
            return {"error": f"Generation error: {str(e)}"}
    
    async def test_connection(self) -> bool:
        """Gemini APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            response = await self.generate_structured_response(
                '{"status": "ok", "message": "Gemini API connection test"} ã¨ã„ã†JSONã‚’è¿”ã—ã¦ãã ã•ã„'
            )
            return response.get("status") == "ok"
        except:
            return False

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_gemini_client():
    client = GeminiClient()
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    print("=== Gemini APIæ¥ç¶šãƒ†ã‚¹ãƒˆ ===")
    is_connected = await client.test_connection()
    print(f"æ¥ç¶šçµæœ: {'æˆåŠŸ' if is_connected else 'å¤±æ•—'}")
    
    # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    print("\n=== æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
    test_prompt = """
    ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
    {
      "intent": "test",
      "message": "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™",
      "timestamp": "2025-01-20"
    }
    """
    
    response = await client.generate_structured_response(test_prompt)
    print(f"å¿œç­”: {response}")

if __name__ == "__main__":
    asyncio.run(test_gemini_client())
```

**å‹•ä½œç¢ºèª**:
```bash
# Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
export GOOGLE_API_KEY="your_actual_api_key"
uv run python src/utils/gemini_client.py

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
uv run python -c "
from src.utils.prompt_templates import format_intent_analysis_prompt
prompt = format_intent_analysis_prompt('ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’è¦‹ãŸã„', ['users', 'orders'])
print(prompt)
"
```

### Step 3.3: æ„å›³åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
**src/agents/intent_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
from src.utils.gemini_client import GeminiClient
from src.utils.prompt_templates import format_intent_analysis_prompt
import asyncio
import os

class IntentAnalysisAgent:
    def __init__(self):
        self.gemini_client = GeminiClient()
        self.available_tables = ["users"]  # å¾Œã§å‹•çš„ã«å–å¾—
        
    async def analyze_intent(self, user_input: str) -> dict:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®æ„å›³åˆ†æ"""
        prompt = format_intent_analysis_prompt(user_input, self.available_tables)
        result = await self.gemini_client.generate_structured_response(prompt)
        return result
    
    async def create_adk_agent(self):
        """ADKã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ"""
        agent = Agent(
            name="intent_analyzer",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’åˆ†æã™ã‚‹å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰ä»¥ä¸‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ï¼š
            1. ãƒ‡ãƒ¼ã‚¿åˆ†æã€å¯è¦–åŒ–ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ã‚¹ã‚­ãƒ¼ãƒç¢ºèªã®ã©ã®æ„å›³ã‹
            2. å¯¾è±¡ã¨ãªã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ã‚«ãƒ©ãƒ 
            3. å¿…è¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
            
            å¿…ãšJSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
            """,
            description="ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
        )
        return agent

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_intent_analysis():
    agent = IntentAnalysisAgent()
    
    test_cases = [
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦",
        "30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹³å‡å¹´é½¢ã‚’è¨ˆç®—ã—ã¦",
        "usersãƒ†ãƒ¼ãƒ–ãƒ«ã®æ§‹é€ ã‚’æ•™ãˆã¦",
        "å¹´é½¢åˆ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’ã‚°ãƒ©ãƒ•ã§è¦‹ãŸã„"
    ]
    
    for test_case in test_cases:
        print(f"\n=== å…¥åŠ›: {test_case} ===")
        result = await agent.analyze_intent(test_case)
        print(f"æ„å›³åˆ†æçµæœ: {result}")

if __name__ == "__main__":
    asyncio.run(test_intent_analysis())
```

**å‹•ä½œç¢ºèª**:
```bash
# æ„å›³åˆ†æãƒ†ã‚¹ãƒˆ
uv run python src/agents/intent_agent.py

# ADK Web UIã§å‹•ä½œç¢ºèª
uv run adk web
# Intent Analysis Agentã¨ã®å¯¾è©±ãƒ†ã‚¹ãƒˆ
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ Step 3**:
- [ ] Gemini APIæ¥ç¶šç¢ºèª
- [ ] æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆç¢ºèª
- [ ] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‹•ä½œç¢ºèª
- [ ] æ„å›³åˆ†ææ©Ÿèƒ½ç¢ºèª
- [ ] JSONå½¢å¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª

## 5. Phase 4: ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ï¼ˆ2-3æ—¥ï¼‰

### Step 4.1: åŸºæœ¬ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
**src/agents/main_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
from toolbox_core import ToolboxClient
from src.utils.gemini_client import GeminiClient
from src.utils.prompt_templates import format_intent_analysis_prompt
import asyncio
import os
from typing import Dict, Any

class MainAgent:
    def __init__(self):
        self.toolbox_url = os.getenv("TOOLBOX_SERVER_URL", "http://localhost:5000")
        self.gemini_client = GeminiClient()
        self.agent = None
        self.conversation_history = []
        
    async def initialize(self):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
        # MCPãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
        toolbox_client = ToolboxClient(self.toolbox_url)
        sql_tools = await toolbox_client.load_toolset("sql-toolset")
        
        # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        self.agent = Agent(
            name="auto_analytics_main",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯Auto Analyticsã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿åˆ†æè¦æ±‚ã‚’ç†è§£ã—ã€é©åˆ‡ã«å‡¦ç†ã—ã¦ãã ã•ã„ã€‚
            
            å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼š
            1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®æ„å›³ã‚’åˆ†æ
            2. å¿…è¦ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±å–å¾—
            3. çµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
            
            åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½ï¼š
            - PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
            - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã®æƒ…å ±å–å¾—
            - ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®ç¢ºèª
            """,
            tools=sql_tools,
            description="Auto Analytics ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼"
        )
    
    async def process_request(self, user_input: str) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã®å‡¦ç†"""
        if not self.agent:
            await self.initialize()
        
        # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
        self.conversation_history.append({
            "role": "user",
            "content": user_input,
            "timestamp": asyncio.get_event_loop().time()
        })
        
        try:
            # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å‡¦ç†
            result = await self.agent.run(user_input)
            
            # å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
            self.conversation_history.append({
                "role": "assistant", 
                "content": str(result),
                "timestamp": asyncio.get_event_loop().time()
            })
            
            return {
                "status": "success",
                "response": result,
                "conversation_id": len(self.conversation_history)
            }
            
        except Exception as e:
            error_response = {
                "status": "error",
                "error": str(e),
                "conversation_id": len(self.conversation_history)
            }
            
            self.conversation_history.append({
                "role": "assistant",
                "content": f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "timestamp": asyncio.get_event_loop().time()
            })
            
            return error_response
    
    def get_conversation_history(self) -> list:
        """ä¼šè©±å±¥æ­´å–å¾—"""
        return self.conversation_history[-10:]  # æœ€æ–°10ä»¶

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_main_agent():
    agent = MainAgent()
    
    test_cases = [
        "ã“ã‚“ã«ã¡ã¯",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã™ã‹ï¼Ÿ",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„",
        "usersãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’æ•™ãˆã¦ãã ã•ã„",
        "30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä½•äººã„ã¾ã™ã‹ï¼Ÿ"
    ]
    
    for test_case in test_cases:
        print(f"\n{'='*50}")
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {test_case}")
        print(f"{'='*50}")
        
        result = await agent.process_request(test_case)
        
        if result["status"] == "success":
            print(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {result['response']}")
        else:
            print(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")
        
        print(f"ä¼šè©±ID: {result['conversation_id']}")

if __name__ == "__main__":
    asyncio.run(test_main_agent())
```

### Step 4.2: ADK Web UIçµ±åˆè¨­å®š
**auto_analytics_project/agent.pyä½œæˆ** (ADKæ¨™æº–æ§‹é€ ):
```python
from src.agents.main_agent import MainAgent
import asyncio

# ADK Web UIç”¨ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
main_agent_instance = None

async def get_main_agent():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—"""
    global main_agent_instance
    if main_agent_instance is None:
        main_agent_instance = MainAgent()
        await main_agent_instance.initialize()
    return main_agent_instance

# ADK Web UIç”¨ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
root_agent = None

async def initialize_root_agent():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
    global root_agent
    agent = await get_main_agent()
    root_agent = agent.agent
    return root_agent

# ADKç”¨ã®åˆæœŸåŒ–
asyncio.create_task(initialize_root_agent())
```

**pyproject.tomlæ›´æ–°**:
```toml
[project]
name = "auto-analytics"
version = "0.1.0"
description = "Auto Analytics AI Agent System"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "google-adk>=0.1.0",
    "google-generativeai>=0.8.0",
    "genai-toolbox>=0.7.0",
    # ... existing dependencies
]

[tool.adk]
agent_module = "auto_analytics_project.agent"
agent_name = "root_agent"
```

**å‹•ä½œç¢ºèª**:
```bash
# MCP Serverèµ·å‹•ç¢ºèª
uv run toolbox --tools-file config/tools.yaml --port 5000 &

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå˜ä½“ãƒ†ã‚¹ãƒˆ
uv run python src/agents/main_agent.py

# ADK Web UIèµ·å‹•
uv run adk web --port 8080

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8080 ã‚¢ã‚¯ã‚»ã‚¹
# Auto Analytics ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®ãƒ•ãƒ«å¯¾è©±ãƒ†ã‚¹ãƒˆ
```

### Step 4.3: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
**src/utils/error_handler.pyä½œæˆ**:
```python
import structlog
from typing import Dict, Any
import traceback

logger = structlog.get_logger()

class AutoAnalyticsError(Exception):
    """Auto AnalyticsåŸºåº•ä¾‹å¤–ã‚¯ãƒ©ã‚¹"""
    pass

class GeminiAPIError(AutoAnalyticsError):
    """Gemini APIé–¢é€£ã‚¨ãƒ©ãƒ¼"""
    pass

class MCPConnectionError(AutoAnalyticsError):
    """MCPæ¥ç¶šã‚¨ãƒ©ãƒ¼"""
    pass

class SQLExecutionError(AutoAnalyticsError):
    """SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"""
    pass

def handle_error(error: Exception, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    error_info = {
        "error_type": type(error).__name__,
        "error_message": str(error),
        "context": context or {},
        "traceback": traceback.format_exc()
    }
    
    logger.error("Auto Analytics Error", **error_info)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    user_messages = {
        "GeminiAPIError": "AIå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
        "MCPConnectionError": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚",
        "SQLExecutionError": "ãƒ‡ãƒ¼ã‚¿å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¯ã‚¨ãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
    }
    
    user_message = user_messages.get(
        type(error).__name__, 
        "äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
    )
    
    return {
        "status": "error",
        "user_message": user_message,
        "technical_details": error_info,
        "suggestions": get_error_suggestions(error)
    }

def get_error_suggestions(error: Exception) -> list:
    """ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã«å¿œã˜ãŸè§£æ±ºææ¡ˆ"""
    suggestions = {
        "GeminiAPIError": [
            "API ã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
            "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            "ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„"
        ],
        "MCPConnectionError": [
            "genai-toolbox MCP ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„", 
            "PostgreSQL ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
            "æ¥ç¶šè¨­å®šï¼ˆãƒ›ã‚¹ãƒˆã€ãƒãƒ¼ãƒˆã€èªè¨¼æƒ…å ±ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        ],
        "SQLExecutionError": [
            "SQL ã‚¯ã‚¨ãƒªã®æ§‹æ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            "ãƒ†ãƒ¼ãƒ–ãƒ«åã€ã‚«ãƒ©ãƒ åãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„",
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¨©é™è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        ]
    }
    
    return suggestions.get(type(error).__name__, [
        "ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
        "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„"
    ])

# ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    test_errors = [
        GeminiAPIError("API rate limit exceeded"),
        MCPConnectionError("Connection timeout"),
        SQLExecutionError("Table 'nonexistent' doesn't exist")
    ]
    
    for error in test_errors:
        print(f"\n=== {type(error).__name__} ãƒ†ã‚¹ãƒˆ ===")
        result = handle_error(error, {"user_input": "test query"})
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {result['user_message']}")
        print(f"ææ¡ˆ: {result['suggestions']}")

if __name__ == "__main__":
    test_error_handling()

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰
# uv run python src/utils/error_handler.py
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ Step 4**:
- [ ] ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºæœ¬å‹•ä½œç¢ºèª
- [ ] ADK Web UIçµ±åˆç¢ºèª
- [ ] ä¼šè©±å±¥æ­´ç®¡ç†ç¢ºèª
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å‹•ä½œç¢ºèª
- [ ] MCP/Geminiçµ±åˆå‹•ä½œç¢ºèª

## 6. Phase 5: SQLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ï¼ˆ3-4æ—¥ï¼‰

### Step 5.1: é«˜åº¦ãªSQLç”Ÿæˆæ©Ÿèƒ½
**config/tools.yamlã«SQLåˆ†æãƒ„ãƒ¼ãƒ«è¿½åŠ **:
```yaml
# ... æ—¢å­˜è¨­å®š ...

tools:
  # ... æ—¢å­˜ãƒ„ãƒ¼ãƒ« ...
  
  analyze-query-performance:
    kind: postgres-sql
    source: analytics-postgres
    description: "ã‚¯ã‚¨ãƒªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"
    statement: EXPLAIN (ANALYZE true, FORMAT JSON) $1
    parameters:
      - name: query
        type: string
        description: "åˆ†æã™ã‚‹SQLã‚¯ã‚¨ãƒª"
  
  get-table-statistics:
    kind: postgres-sql
    source: analytics-postgres
    description: "ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±å–å¾—"
    statement: |
      SELECT 
        schemaname, tablename, n_tup_ins, n_tup_upd, 
        n_tup_del, n_live_tup, n_dead_tup
      FROM pg_stat_user_tables 
      WHERE tablename = $1
    parameters:
      - name: table_name
        type: string
        description: "çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«å"
  
  validate-query-syntax:
    kind: postgres-sql
    source: analytics-postgres
    description: "ã‚¯ã‚¨ãƒªæ§‹æ–‡æ¤œè¨¼"
    statement: EXPLAIN (FORMAT JSON) $1
    parameters:
      - name: query
        type: string
        description: "æ¤œè¨¼ã™ã‚‹ã‚¯ã‚¨ãƒª"

toolsets:
  advanced-sql-toolset:
    tools:
      - test-connection
      - execute-simple-query
      - get-user-list
      - get-table-schema
      - analyze-query-performance
      - get-table-statistics
      - validate-query-syntax
```

**src/agents/sql_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
from toolbox_core import ToolboxClient
from src.utils.gemini_client import GeminiClient
from src.utils.prompt_templates import format_sql_generation_prompt
from src.utils.error_handler import handle_error, SQLExecutionError
import asyncio
import json
import re
from typing import Dict, Any, List

class SQLAgent:
    def __init__(self):
        self.toolbox_url = "http://localhost:5000"
        self.gemini_client = GeminiClient()
        self.agent = None
        self.schema_cache = {}
        
    async def initialize(self):
        """SQLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
        toolbox_client = ToolboxClient(self.toolbox_url)
        sql_tools = await toolbox_client.load_toolset("advanced-sql-toolset")
        
        self.agent = Agent(
            name="sql_specialist",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯SQLã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
            
            1. è‡ªç„¶è¨€èªã‹ã‚‰ã®SQLç”Ÿæˆ
            2. SQLæ§‹æ–‡æ¤œè¨¼
            3. ã‚¯ã‚¨ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            4. ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒåˆ†æ
            
            æ³¨æ„äº‹é …ï¼š
            - SELECTæ–‡ã®ã¿ç”Ÿæˆã—ã¦ãã ã•ã„
            - å±é™ºãªæ“ä½œï¼ˆDELETEã€DROPç­‰ï¼‰ã¯å®Ÿè¡Œã—ã¾ã›ã‚“
            - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’æœ€å„ªå…ˆã«è€ƒæ…®ã—ã¾ã™
            """,
            tools=sql_tools,
            description="é«˜åº¦ãªSQLå‡¦ç†ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ"
        )
    
    async def generate_sql_from_natural_language(self, user_request: str) -> Dict[str, Any]:
        """è‡ªç„¶è¨€èªã‹ã‚‰SQLç”Ÿæˆ"""
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒå–å¾—
            schema_info = await self.get_table_schemas(["users"])
            
            # Geminiã§SQLç”Ÿæˆ
            prompt = f"""
            ä»¥ä¸‹ã®è‡ªç„¶è¨€èªè¦æ±‚ã‚’PostgreSQLã‚¯ã‚¨ãƒªã«å¤‰æ›ã—ã¦ãã ã•ã„ï¼š
            
            è¦æ±‚: {user_request}
            
            åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±:
            {json.dumps(schema_info, indent=2, ensure_ascii=False)}
            
            ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
            {{
              "sql": "SELECTæ–‡ã®SQLã‚¯ã‚¨ãƒª",
              "explanation": "ã‚¯ã‚¨ãƒªã®æ—¥æœ¬èªèª¬æ˜",
              "confidence": "high/medium/low",
              "assumptions": ["å‰ææ¡ä»¶ã®ãƒªã‚¹ãƒˆ"],
              "estimated_complexity": "simple/medium/complex"
            }}
            """
            
            gemini_response = await self.gemini_client.generate_structured_response(prompt)
            
            if "error" in gemini_response:
                return {"status": "error", "error": gemini_response["error"]}
            
            # SQLæ§‹æ–‡æ¤œè¨¼
            sql_query = gemini_response.get("sql", "")
            validation_result = await self.validate_sql_syntax(sql_query)
            
            return {
                "status": "success",
                "sql": sql_query,
                "explanation": gemini_response.get("explanation", ""),
                "confidence": gemini_response.get("confidence", "medium"),
                "validation": validation_result,
                "generated_by": "gemini-2.0-flash-exp"
            }
            
        except Exception as e:
            return handle_error(e, {"user_request": user_request})
    
    async def validate_sql_syntax(self, sql_query: str) -> Dict[str, Any]:
        """SQLæ§‹æ–‡æ¤œè¨¼"""
        if not self.agent:
            await self.initialize()
        
        try:
            # å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
            dangerous_keywords = ["DELETE", "DROP", "TRUNCATE", "ALTER", "CREATE", "INSERT", "UPDATE"]
            upper_sql = sql_query.upper()
            
            for keyword in dangerous_keywords:
                if keyword in upper_sql:
                    return {
                        "is_valid": False,
                        "error": f"å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ãŒå«ã¾ã‚Œã¦ã„ã¾ã™",
                        "security_risk": True
                    }
            
            # PostgreSQLã§ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯ï¼ˆEXPLAINä½¿ç”¨ï¼‰
            result = await self.agent.run(f"ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã®æ§‹æ–‡ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„: {sql_query}")
            
            return {
                "is_valid": True,
                "validation_result": str(result),
                "security_risk": False
            }
            
        except Exception as e:
            return {
                "is_valid": False,
                "error": str(e),
                "security_risk": False
            }
    
    async def execute_sql_with_analysis(self, sql_query: str) -> Dict[str, Any]:
        """SQLå®Ÿè¡Œã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        if not self.agent:
            await self.initialize()
        
        try:
            # æ§‹æ–‡æ¤œè¨¼
            validation = await self.validate_sql_syntax(sql_query)
            if not validation["is_valid"]:
                return {"status": "error", "error": validation["error"]}
            
            # SQLå®Ÿè¡Œ
            execution_result = await self.agent.run(f"ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„: {sql_query}")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            performance_result = await self.agent.run(
                f"ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„: {sql_query}"
            )
            
            return {
                "status": "success",
                "query": sql_query,
                "results": str(execution_result),
                "performance_analysis": str(performance_result),
                "execution_timestamp": asyncio.get_event_loop().time()
            }
            
        except Exception as e:
            return handle_error(e, {"sql_query": sql_query})
    
    async def get_table_schemas(self, table_names: List[str]) -> Dict[str, Any]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        if not self.agent:
            await self.initialize()
        
        schemas = {}
        
        for table_name in table_names:
            if table_name in self.schema_cache:
                schemas[table_name] = self.schema_cache[table_name]
                continue
            
            try:
                schema_result = await self.agent.run(f"{table_name}ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã—ã¦ãã ã•ã„")
                schemas[table_name] = str(schema_result)
                self.schema_cache[table_name] = str(schema_result)
            except Exception as e:
                schemas[table_name] = f"Error: {str(e)}"
        
        return schemas

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_sql_agent():
    agent = SQLAgent()
    
    test_cases = [
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦",
        "30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®äººæ•°ã‚’æ•™ãˆã¦",
        "å¹´é½¢ã®å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦",
        "å¹´é½¢ãŒæœ€ã‚‚é«˜ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¦‹ã¤ã‘ã¦",
        "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒ gmail.com ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œç´¢ã—ã¦"
    ]
    
    for test_case in test_cases:
        print(f"\n{'='*60}")
        print(f"è¦æ±‚: {test_case}")
        print(f"{'='*60}")
        
        # SQLç”Ÿæˆ
        sql_result = await agent.generate_sql_from_natural_language(test_case)
        
        if sql_result["status"] == "success":
            print(f"ç”Ÿæˆã•ã‚ŒãŸSQL: {sql_result['sql']}")
            print(f"èª¬æ˜: {sql_result['explanation']}")
            print(f"ä¿¡é ¼åº¦: {sql_result['confidence']}")
            
            # SQLå®Ÿè¡Œã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            execution_result = await agent.execute_sql_with_analysis(sql_result['sql'])
            
            if execution_result["status"] == "success":
                print(f"å®Ÿè¡Œçµæœ: {execution_result['results']}")
            else:
                print(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {execution_result['error']}")
        else:
            print(f"SQLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {sql_result['error']}")

if __name__ == "__main__":
    asyncio.run(test_sql_agent())
```

**å‹•ä½œç¢ºèª**:
```bash
# MCP Serverå†èµ·å‹•ï¼ˆæ–°ãƒ„ãƒ¼ãƒ«åæ˜ ï¼‰
pkill -f toolbox
uv run toolbox --tools-file config/tools.yaml --port 5000 &

# SQLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå˜ä½“ãƒ†ã‚¹ãƒˆ
uv run python src/agents/sql_agent.py

# ADK Web UIã§SQLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå˜ä½“ãƒ†ã‚¹ãƒˆ
uv run adk web
# SQL Specialistã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®è©³ç´°å¯¾è©±ãƒ†ã‚¹ãƒˆ
```

### Step 5.2: SQLã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆãƒ†ã‚¹ãƒˆ
**tests/test_sql_integration.pyä½œæˆ**:
```python
import pytest
import asyncio
from src.agents.sql_agent import SQLAgent

class TestSQLIntegration:
    """SQL Agentçµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.asyncio
    async def test_sql_generation_basic(self):
        """åŸºæœ¬SQLç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        agent = SQLAgent()
        
        result = await agent.generate_sql_from_natural_language("å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¡¨ç¤ºã—ã¦")
        
        assert result["status"] == "success"
        assert "SELECT" in result["sql"].upper()
        assert "users" in result["sql"].lower()
    
    @pytest.mark.asyncio
    async def test_sql_validation_security(self):
        """SQLã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        agent = SQLAgent()
        
        dangerous_queries = [
            "DELETE FROM users",
            "DROP TABLE users",
            "TRUNCATE users"
        ]
        
        for query in dangerous_queries:
            result = await agent.validate_sql_syntax(query)
            assert result["is_valid"] == False
            assert result["security_risk"] == True
    
    @pytest.mark.asyncio
    async def test_schema_caching(self):
        """ã‚¹ã‚­ãƒ¼ãƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ"""
        agent = SQLAgent()
        
        # åˆå›å–å¾—
        schema1 = await agent.get_table_schemas(["users"])
        assert "users" in schema1
        
        # 2å›ç›®å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ï¼‰
        schema2 = await agent.get_table_schemas(["users"])
        assert schema1 == schema2
        assert "users" in agent.schema_cache

# å®Ÿè¡Œ
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

**å‹•ä½œç¢ºèª**:
```bash
# çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run python -m pytest tests/test_sql_integration.py -v

# ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
uv run python -c "
import asyncio
from src.agents.sql_agent import SQLAgent

async def test_errors():
    agent = SQLAgent()
    # å±é™ºãªSQL
    result = await agent.validate_sql_syntax('DELETE FROM users')
    print('å±é™ºSQLãƒ†ã‚¹ãƒˆ:', result)
    
    # ä¸æ­£ãªæ§‹æ–‡
    result = await agent.validate_sql_syntax('SELCT * FORM users')
    print('æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ:', result)

asyncio.run(test_errors())
"
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ Step 5**:
- [ ] è‡ªç„¶è¨€èªã‹ã‚‰SQLç”Ÿæˆç¢ºèª
- [ ] SQLæ§‹æ–‡æ¤œè¨¼æ©Ÿèƒ½ç¢ºèª
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ç¢ºèª
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†ææ©Ÿèƒ½ç¢ºèª
- [ ] ã‚¹ã‚­ãƒ¼ãƒã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ç¢ºèª
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç¢ºèª

## 7. Phase 6: åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ï¼ˆ3-4æ—¥ï¼‰

### Step 6.1: ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
**src/agents/analysis_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
import pandas as pd
import numpy as np
from typing import Dict, Any, List
import json
import asyncio
from src.utils.gemini_client import GeminiClient
from src.utils.error_handler import handle_error

class AnalysisAgent:
    def __init__(self):
        self.gemini_client = GeminiClient()
        self.agent = None
        
    async def initialize(self):
        """åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
        self.agent = Agent(
            name="data_analyst",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚
            SQLã‚¯ã‚¨ãƒªã®çµæœãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚
            
            æä¾›ã™ã‚‹åˆ†æï¼š
            1. è¨˜è¿°çµ±è¨ˆï¼ˆå¹³å‡ã€ä¸­å¤®å€¤ã€åˆ†æ•£ç­‰ï¼‰
            2. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            3. ç•°å¸¸å€¤æ¤œå‡º
            4. ç›¸é–¢åˆ†æ
            5. ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã®æä¾›
            """,
            description="ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»æ´å¯Ÿç”Ÿæˆã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ"
        )
    
    async def analyze_query_results(self, sql_results: str, query_context: str) -> Dict[str, Any]:
        """ã‚¯ã‚¨ãƒªçµæœã®åˆ†æ"""
        try:
            # SQLçµæœã‚’DataFrameã«å¤‰æ›ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            df = self.parse_sql_results_to_dataframe(sql_results)
            
            if df is None or df.empty:
                return {"status": "error", "error": "ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ"}
            
            # åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—
            basic_stats = self.calculate_basic_statistics(df)
            
            # Geminiã«ã‚ˆã‚‹æ´å¯Ÿç”Ÿæˆ
            insights = await self.generate_insights(df, query_context, basic_stats)
            
            return {
                "status": "success",
                "basic_statistics": basic_stats,
                "insights": insights,
                "data_summary": {
                    "total_rows": len(df),
                    "columns": list(df.columns),
                    "data_types": df.dtypes.to_dict()
                }
            }
            
        except Exception as e:
            return handle_error(e, {"query_context": query_context})
    
    def parse_sql_results_to_dataframe(self, sql_results: str) -> pd.DataFrame:
        """SQLçµæœæ–‡å­—åˆ—ã‚’DataFrameã«å¤‰æ›ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€MCPã‹ã‚‰ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            if "users" in sql_results.lower():
                return pd.DataFrame({
                    'id': [1, 2, 3, 4, 5],
                    'name': ['å¤ªéƒ', 'èŠ±å­', 'æ¬¡éƒ', 'ä¸‰éƒ', 'å››éƒ'],
                    'age': [25, 30, 35, 28, 42],
                    'email': ['taro@example.com', 'hanako@example.com', 
                             'jiro@example.com', 'saburo@example.com', 'shiro@example.com']
                })
            return None
        except:
            return None
    
    def calculate_basic_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—"""
        stats = {}
        
        for column in df.select_dtypes(include=[np.number]).columns:
            stats[column] = {
                "count": int(df[column].count()),
                "mean": float(df[column].mean()),
                "median": float(df[column].median()),
                "std": float(df[column].std()),
                "min": float(df[column].min()),
                "max": float(df[column].max()),
                "q25": float(df[column].quantile(0.25)),
                "q75": float(df[column].quantile(0.75))
            }
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
        for column in df.select_dtypes(include=['object']).columns:
            stats[column] = {
                "count": int(df[column].count()),
                "unique": int(df[column].nunique()),
                "most_common": df[column].mode().iloc[0] if not df[column].mode().empty else None,
                "most_common_count": int(df[column].value_counts().iloc[0]) if not df[column].empty else 0
            }
        
        return stats
    
    async def generate_insights(self, df: pd.DataFrame, query_context: str, basic_stats: Dict) -> Dict[str, Any]:
        """Geminiã«ã‚ˆã‚‹æ´å¯Ÿç”Ÿæˆ"""
        try:
            prompt = f"""
            ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœã‹ã‚‰æ´å¯Ÿã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
            
            ã‚¯ã‚¨ãƒªã®æ–‡è„ˆ: {query_context}
            ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(df)}
            ã‚«ãƒ©ãƒ : {list(df.columns)}
            åŸºæœ¬çµ±è¨ˆ: {json.dumps(basic_stats, ensure_ascii=False, indent=2)}
            
            ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰æ´å¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š
            1. ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã¨å‚¾å‘
            2. æ³¨ç›®ã™ã¹ãæ•°å€¤ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³
            3. ãƒ“ã‚¸ãƒã‚¹çš„ãªç¤ºå”†
            4. æ¨å¥¨ã•ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            
            ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
            {{
              "key_findings": ["ä¸»è¦ãªç™ºè¦‹äº‹é …ã®ãƒªã‚¹ãƒˆ"],
              "trends": ["ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„å‚¾å‘"],
              "anomalies": ["ç•°å¸¸å€¤ã‚„æ³¨æ„ç‚¹"],
              "business_implications": ["ãƒ“ã‚¸ãƒã‚¹çš„ãªç¤ºå”†"],
              "recommended_actions": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
              "confidence_level": "high/medium/low"
            }}
            """
            
            response = await self.gemini_client.generate_structured_response(prompt)
            
            if "error" in response:
                return {"error": response["error"]}
            
            return response
            
        except Exception as e:
            return {"error": str(e)}
    
    async def detect_anomalies(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """ç•°å¸¸å€¤æ¤œå‡º"""
        anomalies = []
        
        for column in df.select_dtypes(include=[np.number]).columns:
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
            
            if not outliers.empty:
                anomalies.append({
                    "column": column,
                    "outlier_count": len(outliers),
                    "outlier_percentage": round(len(outliers) / len(df) * 100, 2),
                    "bounds": {"lower": lower_bound, "upper": upper_bound}
                })
        
        return anomalies

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_analysis_agent():
    agent = AnalysisAgent()
    
    # ã‚µãƒ³ãƒ—ãƒ«SQLçµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    sample_sql_result = """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰5ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼š
    ID: 1, åå‰: å¤ªéƒ, å¹´é½¢: 25
    ID: 2, åå‰: èŠ±å­, å¹´é½¢: 30
    ID: 3, åå‰: æ¬¡éƒ, å¹´é½¢: 35
    """
    
    query_context = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹´é½¢åˆ†å¸ƒã‚’åˆ†æ"
    
    print("=== ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ†ã‚¹ãƒˆ ===")
    result = await agent.analyze_query_results(sample_sql_result, query_context)
    
    if result["status"] == "success":
        print(f"åŸºæœ¬çµ±è¨ˆ: {json.dumps(result['basic_statistics'], ensure_ascii=False, indent=2)}")
        print(f"æ´å¯Ÿ: {json.dumps(result['insights'], ensure_ascii=False, indent=2)}")
    else:
        print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {result['error']}")

if __name__ == "__main__":
    asyncio.run(test_analysis_agent())
```

### Step 6.2: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
**src/agents/report_agent.pyä½œæˆ**:
```python
from google.adk.agents import Agent
import matplotlib.pyplot as plt
import pandas as pd
from typing import Dict, Any, List
import json
import os
from datetime import datetime
import asyncio
from src.utils.gemini_client import GeminiClient

class ReportAgent:
    def __init__(self):
        self.gemini_client = GeminiClient()
        self.agent = None
        self.output_dir = "reports"
        
        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)
        
    async def initialize(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
        self.agent = Agent(
            name="report_generator",
            model="gemini-2.0-flash-exp",
            instruction="""
            ã‚ãªãŸã¯ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚
            ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœã‚’åŸºã«ã€åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
            
            æä¾›ã™ã‚‹æ©Ÿèƒ½ï¼š
            1. HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            2. ã‚°ãƒ©ãƒ•ãƒ»ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
            3. æ´å¯Ÿã®è¦ç´„
            4. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã®ææ¡ˆ
            """,
            description="ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ"
        )
    
    async def generate_html_report(self, analysis_result: Dict[str, Any], query_info: Dict[str, Any]) -> Dict[str, Any]:
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            # ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            report_id = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Geminiã§ãƒ¬ãƒãƒ¼ãƒˆæ§‹é€ åŒ–
            report_content = await self.structure_report_content(analysis_result, query_info)
            
            # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
            html_content = self.create_html_template(report_content, report_id)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            report_path = os.path.join(self.output_dir, f"{report_id}.html")
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            return {
                "status": "success",
                "report_id": report_id,
                "report_path": report_path,
                "report_url": f"file://{os.path.abspath(report_path)}",
                "generated_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    async def structure_report_content(self, analysis_result: Dict[str, Any], query_info: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ã®æ§‹é€ åŒ–"""
        prompt = f"""
        ä»¥ä¸‹ã®åˆ†æçµæœã‚’åŸºã«ã€ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®å†…å®¹ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š
        
        ã‚¯ã‚¨ãƒªæƒ…å ±: {json.dumps(query_info, ensure_ascii=False)}
        åˆ†æçµæœ: {json.dumps(analysis_result, ensure_ascii=False)}
        
        ä»¥ä¸‹ã®JSONå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆæ§‹é€ ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
          "title": "ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«",
          "executive_summary": "è¦ç´„ï¼ˆ2-3æ–‡ï¼‰",
          "key_metrics": ["ä¸»è¦æŒ‡æ¨™ã®ãƒªã‚¹ãƒˆ"],
          "findings": ["ç™ºè¦‹äº‹é …ã®ãƒªã‚¹ãƒˆ"],
          "recommendations": ["æ¨å¥¨äº‹é …ã®ãƒªã‚¹ãƒˆ"],
          "next_steps": ["æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—"],
          "data_quality_notes": ["ãƒ‡ãƒ¼ã‚¿å“è³ªã«é–¢ã™ã‚‹æ³¨æ„äº‹é …"]
        }}
        """
        
        response = await self.gemini_client.generate_structured_response(prompt)
        return response if "error" not in response else {"title": "Analysis Report", "executive_summary": "åˆ†æå®Œäº†"}
    
    def create_html_template(self, content: Dict[str, Any], report_id: str) -> str:
        """HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ"""
        html = f"""
        <!DOCTYPE html>
        <html lang="ja">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>{content.get('title', 'Auto Analytics Report')}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}
                .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; }}
                .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007cba; }}
                .metric {{ background-color: #e8f4f8; padding: 10px; margin: 5px 0; border-radius: 3px; }}
                .recommendation {{ background-color: #fff2e8; padding: 10px; margin: 5px 0; border-radius: 3px; }}
                .footer {{ color: #666; font-size: 0.9em; margin-top: 40px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>{content.get('title', 'Auto Analytics Report')}</h1>
                <p><strong>ãƒ¬ãƒãƒ¼ãƒˆID:</strong> {report_id}</p>
                <p><strong>ç”Ÿæˆæ—¥æ™‚:</strong> {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>
            </div>
            
            <div class="section">
                <h2>ğŸ“Š è¦ç´„</h2>
                <p>{content.get('executive_summary', 'åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚')}</p>
            </div>
            
            <div class="section">
                <h2>ğŸ” ä¸»è¦æŒ‡æ¨™</h2>
                {self._format_list_items(content.get('key_metrics', []), 'metric')}
            </div>
            
            <div class="section">
                <h2>ğŸ’¡ ç™ºè¦‹äº‹é …</h2>
                {self._format_list_items(content.get('findings', []), 'finding')}
            </div>
            
            <div class="section">
                <h2>ğŸ¯ æ¨å¥¨äº‹é …</h2>
                {self._format_list_items(content.get('recommendations', []), 'recommendation')}
            </div>
            
            <div class="section">
                <h2>ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h2>
                {self._format_list_items(content.get('next_steps', []), 'next-step')}
            </div>
            
            <div class="footer">
                <p>ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯Auto Analytics AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚</p>
            </div>
        </body>
        </html>
        """
        return html
    
    def _format_list_items(self, items: List[str], css_class: str) -> str:
        """ãƒªã‚¹ãƒˆé …ç›®ã®HTML ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not items:
            return "<p>é …ç›®ãŒã‚ã‚Šã¾ã›ã‚“ã€‚</p>"
        
        return "".join([f'<div class="{css_class}">â€¢ {item}</div>' for item in items])
    
    def create_simple_chart(self, data: Dict[str, Any], chart_type: str = "bar") -> str:
        """ç°¡å˜ãªãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
        try:
            plt.figure(figsize=(10, 6))
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
            if chart_type == "bar":
                categories = ['ã‚«ãƒ†ã‚´ãƒªA', 'ã‚«ãƒ†ã‚´ãƒªB', 'ã‚«ãƒ†ã‚´ãƒªC']
                values = [23, 45, 56]
                plt.bar(categories, values)
                plt.title('ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœ')
                plt.ylabel('å€¤')
            
            # ãƒãƒ£ãƒ¼ãƒˆä¿å­˜
            chart_path = os.path.join(self.output_dir, f"chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return chart_path
            
        except Exception as e:
            return f"ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_report_agent():
    agent = ReportAgent()
    
    # ã‚µãƒ³ãƒ—ãƒ«åˆ†æçµæœ
    sample_analysis = {
        "status": "success",
        "basic_statistics": {
            "age": {"mean": 30.4, "median": 30, "std": 4.5}
        },
        "insights": {
            "key_findings": ["å¹³å‡å¹´é½¢ã¯30.4æ­³", "æ¨™æº–åå·®ã¯4.5æ­³ã§åˆ†æ•£ã¯å°ã•ã„"],
            "business_implications": ["è‹¥ã„ä¸–ä»£ãŒä¸­å¿ƒ", "å¹´é½¢å±¤ãŒæ¯”è¼ƒçš„å‡ä¸€"]
        }
    }
    
    sample_query_info = {
        "sql": "SELECT age FROM users",
        "context": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å¹´é½¢åˆ†æ"
    }
    
    print("=== ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
    result = await agent.generate_html_report(sample_analysis, sample_query_info)
    
    if result["status"] == "success":
        print(f"ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆæˆåŠŸ: {result['report_path']}")
        print(f"ãƒ¬ãƒãƒ¼ãƒˆURL: {result['report_url']}")
    else:
        print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {result['error']}")

if __name__ == "__main__":
    asyncio.run(test_report_agent())
```

**å‹•ä½œç¢ºèª**:
```bash
# åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
uv run python src/agents/analysis_agent.py

# ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
uv run python src/agents/report_agent.py

# ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
ls -la reports/
# HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§ç¢ºèª
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ Step 6**:
- [ ] ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œç¢ºèª
- [ ] åŸºæœ¬çµ±è¨ˆè¨ˆç®—ç¢ºèª
- [ ] æ´å¯Ÿç”Ÿæˆæ©Ÿèƒ½ç¢ºèª
- [ ] HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç¢ºèª
- [ ] ãƒãƒ£ãƒ¼ãƒˆä½œæˆæ©Ÿèƒ½ç¢ºèª

## 8. Phase 7: çµ±åˆãƒ†ã‚¹ãƒˆãƒ»å®Œæˆï¼ˆ2-3æ—¥ï¼‰

### Step 8.1: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰çµ±åˆ
**src/main.pyæ›´æ–°ï¼ˆå®Œå…¨ç‰ˆï¼‰**:
```python
from google.adk.agents import Agent
from toolbox_core import ToolboxClient
from src.agents.main_agent import MainAgent
from src.agents.sql_agent import SQLAgent
from src.agents.analysis_agent import AnalysisAgent
from src.agents.report_agent import ReportAgent
import asyncio
import os

class AutoAnalyticsSystem:
    def __init__(self):
        self.main_agent = MainAgent()
        self.sql_agent = SQLAgent()
        self.analysis_agent = AnalysisAgent()
        self.report_agent = ReportAgent()
        self.initialized = False
    
    async def initialize(self):
        """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åˆæœŸåŒ–"""
        if self.initialized:
            return
        
        print("ğŸš€ Auto Analytics ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        await self.main_agent.initialize()
        await self.sql_agent.initialize()
        await self.analysis_agent.initialize()
        await self.report_agent.initialize()
        
        self.initialized = True
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    async def process_full_workflow(self, user_request: str) -> dict:
        """å®Œå…¨ãªåˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        if not self.initialized:
            await self.initialize()
        
        print(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: {user_request}")
        
        # Step 1: ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§è¦æ±‚å‡¦ç†
        main_result = await self.main_agent.process_request(user_request)
        if main_result["status"] != "success":
            return main_result
        
        print("âœ… Step 1: è¦æ±‚ç†è§£å®Œäº†")
        
        # Step 2: SQLç”Ÿæˆãƒ»å®Ÿè¡Œ
        sql_result = await self.sql_agent.generate_sql_from_natural_language(user_request)
        if sql_result["status"] != "success":
            return sql_result
        
        print(f"âœ… Step 2: SQLç”Ÿæˆå®Œäº† - {sql_result['sql']}")
        
        execution_result = await self.sql_agent.execute_sql_with_analysis(sql_result['sql'])
        if execution_result["status"] != "success":
            return execution_result
        
        print("âœ… Step 3: SQLå®Ÿè¡Œå®Œäº†")
        
        # Step 4: ãƒ‡ãƒ¼ã‚¿åˆ†æ
        analysis_result = await self.analysis_agent.analyze_query_results(
            execution_result['results'], user_request
        )
        if analysis_result["status"] != "success":
            return analysis_result
        
        print("âœ… Step 4: ãƒ‡ãƒ¼ã‚¿åˆ†æå®Œäº†")
        
        # Step 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_result = await self.report_agent.generate_html_report(
            analysis_result, 
            {"sql": sql_result['sql'], "context": user_request}
        )
        if report_result["status"] != "success":
            return report_result
        
        print(f"âœ… Step 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº† - {report_result['report_path']}")
        
        return {
            "status": "success",
            "workflow_completed": True,
            "steps": {
                "main_agent": main_result,
                "sql_generation": sql_result,
                "sql_execution": execution_result,
                "data_analysis": analysis_result,
                "report_generation": report_result
            },
            "final_report": report_result['report_url']
        }

# ADK Web UIç”¨ã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
auto_analytics_system = AutoAnalyticsSystem()

async def create_root_agent():
    """ADKç”¨ãƒ«ãƒ¼ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ"""
    await auto_analytics_system.initialize()
    
    root_agent = Agent(
        name="auto_analytics_root",
        model="gemini-2.0-flash-exp",
        instruction="""
        ã‚ãªãŸã¯Auto Analytics AIã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿åˆ†æè¦æ±‚ã‚’å—ã‘å–ã‚Šã€å®Œå…¨ãªåˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
        
        ã‚·ã‚¹ãƒ†ãƒ ã®æ©Ÿèƒ½ï¼š
        1. è‡ªç„¶è¨€èªã§ã®åˆ†æè¦æ±‚ç†è§£
        2. SQLã‚¯ã‚¨ãƒªè‡ªå‹•ç”Ÿæˆãƒ»å®Ÿè¡Œ
        3. ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»æ´å¯Ÿç”Ÿæˆ
        4. HTMLãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ä½œæˆ
        
        ä½¿ç”¨ä¾‹ï¼š
        - "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹´é½¢åˆ†å¸ƒã‚’åˆ†æã—ã¦"
        - "30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’æ•™ãˆã¦"
        - "å¹´é½¢ã®çµ±è¨ˆæƒ…å ±ã‚’ãƒ¬ãƒãƒ¼ãƒˆã«ã—ã¦"
        """,
        description="Auto Analytics çµ±åˆã‚·ã‚¹ãƒ†ãƒ "
    )
    
    return root_agent

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    system = AutoAnalyticsSystem()
    
    # ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œãƒ†ã‚¹ãƒˆ
    test_requests = [
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦",
        "30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çµ±è¨ˆåˆ†æã‚’ã—ã¦",
        "å¹´é½¢ã®å¹³å‡å€¤ã¨åˆ†æ•£ã‚’ãƒ¬ãƒãƒ¼ãƒˆã«ã¾ã¨ã‚ã¦"
    ]
    
    for request in test_requests:
        print(f"\n{'='*80}")
        print(f"ğŸ” ãƒ†ã‚¹ãƒˆè¦æ±‚: {request}")
        print(f"{'='*80}")
        
        result = await system.process_full_workflow(request)
        
        if result["status"] == "success":
            print(f"ğŸ‰ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†!")
            print(f"ğŸ“Š æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ: {result['final_report']}")
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown error')}")

if __name__ == "__main__":
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å®Ÿè¡Œ
    asyncio.run(main())

# ADK Web UIç”¨
root_agent = None
asyncio.create_task(create_root_agent().then(lambda agent: globals().update(root_agent=agent)))
```

### Step 8.2: æœ€çµ‚å‹•ä½œç¢ºèªæ‰‹é †
```bash
# 1. å…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ç¢ºèª
echo "=== ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ç¢ºèª ==="

# PostgreSQLç¢ºèª
psql -h localhost -U analytics_user -d analytics -c "SELECT COUNT(*) FROM users;"

# genai-toolbox MCP Serverç¢ºèª
curl http://localhost:5000/health

# 2. å®Œå…¨çµ±åˆãƒ†ã‚¹ãƒˆ
echo "=== å®Œå…¨çµ±åˆãƒ†ã‚¹ãƒˆ ==="
uv run python src/main.py

# 3. ADK Web UIæœ€çµ‚ãƒ†ã‚¹ãƒˆ
echo "=== ADK Web UIæœ€çµ‚ãƒ†ã‚¹ãƒˆ ==="
uv run adk web --port 8080

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ä»¥ä¸‹ã‚’ãƒ†ã‚¹ãƒˆï¼š
# - "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹´é½¢åˆ†æã‚’ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦"
# - "30æ­³ä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’æ•™ãˆã¦"
# - "å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‚’ã¾ã¨ã‚ã¦"

# 4. ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
echo "=== ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆç¢ºèª ==="
ls -la reports/
open reports/*.html  # macOSã®å ´åˆ
```

### Step 8.3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯
**tests/test_performance.pyä½œæˆ**:
```python
import asyncio
import time
import pytest
from src.main import AutoAnalyticsSystem

class TestPerformance:
    @pytest.mark.asyncio
    async def test_end_to_end_performance(self):
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        system = AutoAnalyticsSystem()
        
        start_time = time.time()
        
        result = await system.process_full_workflow("ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’åˆ†æã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦")
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # 3ç§’ä»¥å†…ã§ã®å®Œäº†ã‚’ç¢ºèª
        assert execution_time < 3.0, f"å‡¦ç†æ™‚é–“ãŒé…ã™ãã¾ã™: {execution_time}ç§’"
        assert result["status"] == "success"
        
        print(f"å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰
# uv run python tests/test_performance.py
```

**æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] PostgreSQLæ¥ç¶šæ­£å¸¸
- [ ] genai-toolbox MCP Serverå‹•ä½œæ­£å¸¸
- [ ] Gemini APIæ¥ç¶šæ­£å¸¸
- [ ] å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–æˆåŠŸ
- [ ] ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‹•ä½œ
- [ ] HTMLãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆæˆåŠŸ
- [ ] ADK Web UIå®Œå…¨å‹•ä½œ
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ­£å¸¸
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶æº€è¶³ï¼ˆ3ç§’ä»¥å†…ï¼‰
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯é€šé

## 9. é‹ç”¨ãƒ»ä¿å®ˆæ‰‹é †

### 9.1 æ—¥å¸¸é‹ç”¨ãƒã‚§ãƒƒã‚¯
```bash
#!/bin/bash
# daily_check.sh - æ—¥æ¬¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

echo "=== Auto Analytics æ—¥æ¬¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ ==="

# PostgreSQLæ¥ç¶šç¢ºèªï¼ˆdevcontainerç’°å¢ƒï¼‰
echo "1. PostgreSQLæ¥ç¶šç¢ºèª"
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics -c "SELECT 'OK' as status;" || echo "âŒ PostgreSQLæ¥ç¶šå¤±æ•—"

# MCP Serverç¢ºèª
echo "2. MCP Serverç¢ºèª"
curl -f http://localhost:5000/health || echo "âŒ MCP Serveræ¥ç¶šå¤±æ•—"

# Gemini APIç¢ºèª
echo "3. Gemini APIç¢ºèª"
uv run python -c "
import os
import google.generativeai as genai
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
model = genai.GenerativeModel('gemini-2.0-flash-exp')
response = model.generate_content('Hello')
print('âœ… Gemini APIæ­£å¸¸' if response else 'âŒ Gemini APIç•°å¸¸')
"

# ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºèª
echo "4. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºèª"
df -h | grep -E "(filesystem|/workspace)"

echo "=== ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº† ==="
```

### 9.2 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
```bash
# ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

# 1. MCP Serveræ¥ç¶šå¤±æ•—
pkill -f toolbox
uv run toolbox --tools-file config/tools.yaml --port 5000 &

# 2. PostgreSQLæ¥ç¶šå¤±æ•—ï¼ˆdevcontainerç’°å¢ƒï¼‰
# devcontainerå†…ã§ã¯.devcontainer/docker-compose.ymlã§ç®¡ç†
echo "PostgreSQL ã¯ .devcontainer/docker-compose.yml ã§ç®¡ç†ã•ã‚Œã¦ã„ã¾ã™"
echo "VS Code devcontainer ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„"

# ã¾ãŸã¯ç›´æ¥ç¢ºèª
PGPASSWORD=password psql -h localhost -U postgres -c "SELECT 1;" || echo "PostgreSQL ã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªãŒå¿…è¦"

# 3. Gemini APIåˆ¶é™ã‚¨ãƒ©ãƒ¼
# APIã‚­ãƒ¼ç¢ºèªãƒ»ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¾…æ©Ÿ

# 4. ãƒ¡ãƒ¢ãƒªä¸è¶³
# ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
free -h
ps aux --sort=-%mem | head
```

## 10. uvç’°å¢ƒ ä¾¿åˆ©ã‚³ãƒãƒ³ãƒ‰é›†

### 10.1 åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰
```bash
# ä¾å­˜é–¢ä¿‚åŒæœŸï¼ˆåˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼‰
uv sync

# æ–°ã—ã„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¿½åŠ 
uv add package-name

# é–‹ç™ºä¾å­˜é–¢ä¿‚è¿½åŠ 
uv add --dev package-name

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å‰Šé™¤
uv remove package-name

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã§ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
uv run command

# Python REPLèµ·å‹•
uv run python

# ä¾å­˜é–¢ä¿‚ãƒ„ãƒªãƒ¼è¡¨ç¤º
uv tree

# ç’°å¢ƒæƒ…å ±è¡¨ç¤º
uv info
```

### 10.2 é–‹ç™ºæ™‚ã«ã‚ˆãä½¿ã†ã‚³ãƒãƒ³ãƒ‰ï¼ˆdevcontainerå†…ï¼‰
```bash
# Auto Analytics èµ·å‹•
uv run python src/main.py

# ADK Web UIèµ·å‹•ï¼ˆdevcontainer ãƒãƒ¼ãƒˆè»¢é€ã‚ã‚Šï¼‰
uv run adk web --host 0.0.0.0 --port 8080

# MCP Serverèµ·å‹•
uv run toolbox --tools-file config/tools.yaml --port 5000

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run python -m pytest tests/ -v

# ç‰¹å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
uv run python src/agents/main_agent.py

# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¨­å®šæ¸ˆã¿ã®å ´åˆï¼‰
uv run black src/
uv run isort src/
```

### 10.3 devcontainer PostgreSQLç®¡ç†
```bash
# PostgreSQLæ¥ç¶šï¼ˆAnalyticsç”¨ï¼‰
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics

# PostgreSQLæ¥ç¶šï¼ˆç®¡ç†è€…ï¼‰
PGPASSWORD=password psql -h localhost -U postgres

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹ç¢ºèª
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics -c "
SELECT 
    current_database() as database,
    current_user as user,
    version() as postgres_version;
"

# ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ç¢ºèª
PGPASSWORD=secure_password psql -h localhost -U analytics_user -d analytics -c "\dt"

# Analytics ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†åˆæœŸåŒ–
PGPASSWORD=password psql -h localhost -U postgres -f /workspace/init_analytics.sql
```

### 10.4 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
```bash
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
uv cache clean

# ç’°å¢ƒå†æ§‹ç¯‰
rm -rf .venv uv.lock
uv sync

# Pythonç‰ˆç¢ºèªãƒ»å¤‰æ›´
uv python list
uv python pin 3.11
```

---

ã“ã®é–‹ç™ºæ‰‹é †æ›¸ã«ã‚ˆã‚Šã€uvã‚’æ´»ç”¨ã—ãŸæ®µéšçš„ã§ç¢ºå®Ÿãªå®Ÿè£…ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚å„ã‚¹ãƒ†ãƒƒãƒ—ã§å‹•ä½œç¢ºèªã‚’è¡Œã„ãªãŒã‚‰é€²ã‚ã‚‹ã“ã¨ã§ã€å•é¡Œã®æ—©æœŸç™ºè¦‹ã¨ä¿®æ­£ãŒå¯èƒ½ã§ã™ã€‚