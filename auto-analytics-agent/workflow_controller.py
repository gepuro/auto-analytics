"""
ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 
æƒ…å ±ã®å®Œå…¨æ€§ã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾è©±ã¨åˆ†æãƒ•ãƒ­ãƒ¼ã‚’å‹•çš„ã«åˆ¶å¾¡
"""

import json
import re
from typing import Dict, Any, Optional, Tuple, List
from datetime import datetime

class WorkflowController:
    """
    åˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å‹•çš„åˆ¶å¾¡ã‚’è¡Œã†ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        self.state = {
            "workflow_phase": "request_interpretation",
            "information_status": "unknown",
            "user_input_required": False,
            "clarification_questions": [],
            "analysis_context": {},
            "workflow_history": []
        }
    
    def analyze_information_gap(self, gap_analysis_output: str) -> Dict[str, Any]:
        """
        æƒ…å ±ä¸è¶³æ¤œå‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›ã‚’åˆ†æã—ã¦æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
        
        Args:
            gap_analysis_output: æƒ…å ±ä¸è¶³æ¤œå‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›
            
        Returns:
            æ¬¡ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°
        """
        try:
            # JSONå½¢å¼ã®å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹
            if gap_analysis_output.strip().startswith('{'):
                gap_data = json.loads(gap_analysis_output)
                status = gap_data.get("status", "needs_clarification")
                missing_info = gap_data.get("missing_info", [])
                ambiguous_points = gap_data.get("ambiguous_points", [])
                confidence = gap_data.get("confidence_score", 0.0)
            else:
                # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å ´åˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§åˆ¤å®š
                status = self._extract_status_from_text(gap_analysis_output)
                missing_info = self._extract_missing_info_from_text(gap_analysis_output)
                ambiguous_points = self._extract_ambiguous_points_from_text(gap_analysis_output)
                confidence = self._estimate_confidence_from_text(gap_analysis_output)
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ±ºå®š
            if status == "sufficient" and confidence > 0.7:
                return {
                    "action": "continue_analysis",
                    "next_phase": "schema_exploration",
                    "user_input_required": False,
                    "message": "æƒ…å ±ãŒååˆ†ã«æƒã„ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’é–‹å§‹ã—ã¾ã™ã€‚",
                    "confidence": confidence
                }
            else:
                return {
                    "action": "request_clarification",
                    "next_phase": "user_confirmation",
                    "user_input_required": True,
                    "missing_info": missing_info,
                    "ambiguous_points": ambiguous_points,
                    "message": "è¿½åŠ æƒ…å ±ãŒå¿…è¦ã§ã™ã€‚è©³ç´°ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚",
                    "confidence": confidence
                }
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ç¢ºèªã‚’æ±‚ã‚ã‚‹
            return {
                "action": "request_clarification",
                "next_phase": "user_confirmation", 
                "user_input_required": True,
                "error": str(e),
                "message": "åˆ†æã‚’é–‹å§‹ã™ã‚‹å‰ã«ã€ã„ãã¤ã‹ç¢ºèªã•ã›ã¦ãã ã•ã„ã€‚"
            }
    
    def _extract_status_from_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æƒ…å ±ã®å®Œå…¨æ€§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æŠ½å‡º"""
        text_lower = text.lower()
        if any(keyword in text_lower for keyword in ["sufficient", "ååˆ†", "å®Œå…¨", "å•é¡Œãªã—"]):
            return "sufficient"
        elif any(keyword in text_lower for keyword in ["needs_clarification", "è¦ç¢ºèª", "ä¸è¶³", "æ›–æ˜§"]):
            return "needs_clarification"
        else:
            return "needs_clarification"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç¢ºèªè¦æ±‚
    
    def _extract_missing_info_from_text(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¸è¶³æƒ…å ±ã‚’æŠ½å‡º"""
        missing_patterns = [
            r"ä¸è¶³.*?æƒ…å ±[ï¼š:]?\s*([^ã€‚\n]*)",
            r"missing.*?info[ï¼š:]?\s*([^ã€‚\n]*)",
            r"å¿…è¦.*?æƒ…å ±[ï¼š:]?\s*([^ã€‚\n]*)",
        ]
        
        missing_info = []
        for pattern in missing_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            missing_info.extend(matches)
        
        return [info.strip() for info in missing_info if info.strip()]
    
    def _extract_ambiguous_points_from_text(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ›–æ˜§ãªç‚¹ã‚’æŠ½å‡º"""
        ambiguous_patterns = [
            r"æ›–æ˜§.*?ç‚¹[ï¼š:]?\s*([^ã€‚\n]*)",
            r"ambiguous.*?points?[ï¼š:]?\s*([^ã€‚\n]*)",
            r"ä¸æ˜ç¢º.*?éƒ¨åˆ†[ï¼š:]?\s*([^ã€‚\n]*)",
        ]
        
        ambiguous_points = []
        for pattern in ambiguous_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            ambiguous_points.extend(matches)
        
        return [point.strip() for point in ambiguous_points if point.strip()]
    
    def _estimate_confidence_from_text(self, text: str) -> float:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¿¡é ¼åº¦ã‚’æ¨å®š"""
        confidence_keywords = {
            "ç¢ºå®Ÿ": 0.9, "ååˆ†": 0.8, "å•é¡Œãªã—": 0.8, "æ˜ç¢º": 0.7,
            "sufficient": 0.8, "clear": 0.7, "complete": 0.9,
            "æ›–æ˜§": 0.3, "ä¸è¶³": 0.2, "ä¸æ˜": 0.2, "ç¢ºèªå¿…è¦": 0.1,
            "ambiguous": 0.3, "missing": 0.2, "unclear": 0.2
        }
        
        text_lower = text.lower()
        confidence_scores = []
        
        for keyword, score in confidence_keywords.items():
            if keyword in text_lower:
                confidence_scores.append(score)
        
        return sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.5
    
    def generate_clarification_questions(self, 
                                       original_request: str,
                                       missing_info: List[str],
                                       ambiguous_points: List[str]) -> str:
        """
        ä¸è¶³æƒ…å ±ã«åŸºã¥ã„ã¦å…·ä½“çš„ãªç¢ºèªè³ªå•ã‚’ç”Ÿæˆ
        
        Args:
            original_request: å…ƒã®åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            missing_info: ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±
            ambiguous_points: æ›–æ˜§ãªç‚¹
            
        Returns:
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ç¢ºèªè³ªå•ãƒ†ã‚­ã‚¹ãƒˆ
        """
        questions = []
        
        # æ¨™æº–çš„ãªç¢ºèªé …ç›®
        standard_questions = {
            "æœŸé–“": "åˆ†æå¯¾è±¡ã®æœŸé–“ã‚’æ•™ãˆã¦ãã ã•ã„ï¼š\n"
                   "â€¢ ä»Šæœˆï¼ˆç¾åœ¨ã®æœˆï¼‰\n"
                   "â€¢ å…ˆæœˆ\n" 
                   "â€¢ ä»Šå¹´åº¦\n"
                   "â€¢ æ˜¨å¹´åº¦\n"
                   "â€¢ ç‰¹å®šæœŸé–“ï¼ˆå…·ä½“çš„ãªé–‹å§‹æ—¥-çµ‚äº†æ—¥ï¼‰",
                   
            "ç²’åº¦": "ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆãƒ¬ãƒ™ãƒ«ã‚’æ•™ãˆã¦ãã ã•ã„ï¼š\n"
                   "â€¢ æ—¥åˆ¥\n"
                   "â€¢ é€±åˆ¥\n"
                   "â€¢ æœˆåˆ¥\n"
                   "â€¢ å¹´åˆ¥\n"
                   "â€¢ ãã®ä»–ï¼ˆå…·ä½“çš„ã«ï¼‰",
                   
            "å¯¾è±¡": "åˆ†æå¯¾è±¡ã®è©³ç´°ã‚’æ•™ãˆã¦ãã ã•ã„ï¼š\n"
                   "â€¢ å…¨ä½“\n"
                   "â€¢ ç‰¹å®šå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹\n"
                   "â€¢ ç‰¹å®šåœ°åŸŸãƒ»åº—èˆ—\n"
                   "â€¢ ç‰¹å®šé¡§å®¢å±¤\n"
                   "â€¢ ãã®ä»–ï¼ˆå…·ä½“çš„ã«ï¼‰",
                   
            "æ¯”è¼ƒ": "æ¯”è¼ƒåˆ†æã®è¦å¦ã‚’æ•™ãˆã¦ãã ã•ã„ï¼š\n"
                   "â€¢ å‰å¹´åŒæœŸã¨ã®æ¯”è¼ƒ\n"
                   "â€¢ å‰æœˆã¨ã®æ¯”è¼ƒ\n"
                   "â€¢ ç›®æ¨™å€¤ã¨ã®æ¯”è¼ƒ\n"
                   "â€¢ æ¯”è¼ƒä¸è¦\n"
                   "â€¢ ãã®ä»–ï¼ˆå…·ä½“çš„ã«ï¼‰"
        }
        
        # ä¸è¶³æƒ…å ±ã«åŸºã¥ãè³ªå•ç”Ÿæˆ
        for info in missing_info:
            for key, question in standard_questions.items():
                if key in info or any(keyword in info for keyword in ["æ™‚é–“", "æœŸé–“", "ã„ã¤"]):
                    if key == "æœŸé–“":
                        questions.append(f"ğŸ“… **{question}**")
                elif any(keyword in info for keyword in ["ãƒ¬ãƒ™ãƒ«", "ç²’åº¦", "å˜ä½"]):
                    if key == "ç²’åº¦":
                        questions.append(f"ğŸ“Š **{question}**")
                elif any(keyword in info for keyword in ["å¯¾è±¡", "ä½•ã‚’", "ã©ã‚Œã‚’"]):
                    if key == "å¯¾è±¡":
                        questions.append(f"ğŸ¯ **{question}**")
                elif any(keyword in info for keyword in ["æ¯”è¼ƒ", "å¯¾æ¯”"]):
                    if key == "æ¯”è¼ƒ":
                        questions.append(f"ğŸ“ˆ **{question}**")
        
        # æ›–æ˜§ãªç‚¹ã«åŸºã¥ãè³ªå•ç”Ÿæˆ
        for point in ambiguous_points:
            questions.append(f"â“ **{point}ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„**")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè³ªå•ï¼ˆä½•ã‚‚ç‰¹å®šã§ããªã„å ´åˆï¼‰
        if not questions:
            questions = [
                "ğŸ“… **åˆ†ææœŸé–“**: ã„ã¤ã®æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¾ã™ã‹ï¼Ÿ",
                "ğŸ“Š **é›†è¨ˆãƒ¬ãƒ™ãƒ«**: ã©ã®å˜ä½ã§åˆ†æã—ã¾ã™ã‹ï¼Ÿï¼ˆæ—¥åˆ¥ã€æœˆåˆ¥ãªã©ï¼‰",
                "ğŸ¯ **åˆ†æå¯¾è±¡**: ä½•ã‚’åˆ†æå¯¾è±¡ã¨ã—ã¾ã™ã‹ï¼Ÿ"
            ]
        
        # è³ªå•ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        question_text = f"""
åˆ†æã®ã”ä¾é ¼ã‚’ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚

**ğŸ“‹ ãŠèã‹ã›ã„ãŸã ããŸã„å†…å®¹ï¼š**

{chr(10).join(f"{i+1}. {q}" for i, q in enumerate(questions))}

ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’ãŠæ•™ãˆã„ãŸã ã‘ã‚Œã°ã€ã‚ˆã‚Šæ­£ç¢ºã§æœ‰ç”¨ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ãŠä½œã‚Šã§ãã¾ã™ã€‚
"""
        
        return question_text.strip()
    
    def process_user_response(self, 
                            original_request: str,
                            clarification_questions: str,
                            user_response: str) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’å‡¦ç†ã—ã¦å®Œæˆã—ãŸåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            original_request: å…ƒã®åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            clarification_questions: é€ä¿¡ã—ãŸç¢ºèªè³ªå•
            user_response: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å›ç­”
            
        Returns:
            çµ±åˆã•ã‚ŒãŸå®Œå…¨ãªåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        """
        completed_request = f"""
ã€å®Œæˆã—ãŸåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆã€‘

**å…ƒã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**: {original_request}

**è¿½åŠ ã„ãŸã ã„ãŸæƒ…å ±**: {user_response}

**çµ±åˆã•ã‚ŒãŸåˆ†æè¦ä»¶**:
{self._integrate_request_and_response(original_request, user_response)}

ã“ã‚Œã§åˆ†æã«å¿…è¦ãªæƒ…å ±ãŒæƒã„ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª¿æŸ»ã‚’é–‹å§‹ã—ã¾ã™ã€‚

ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}
"""
        
        return completed_request.strip()
    
    def _integrate_request_and_response(self, original: str, response: str) -> str:
        """å…ƒã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”ã‚’çµ±åˆ"""
        # ã‚·ãƒ³ãƒ—ãƒ«ãªçµ±åˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªè‡ªç„¶è¨€èªå‡¦ç†ãŒå¿…è¦ï¼‰
        integration = f"â€¢ åˆ†æå†…å®¹: {original}\nâ€¢ è©³ç´°æ¡ä»¶: {response}"
        
        return integration
    
    def update_workflow_state(self, phase: str, data: Dict[str, Any]):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ã‚’æ›´æ–°"""
        self.state["workflow_phase"] = phase
        self.state["analysis_context"].update(data)
        self.state["workflow_history"].append({
            "timestamp": datetime.now().isoformat(),
            "phase": phase,
            "data": data
        })
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            "current_phase": self.state["workflow_phase"],
            "information_status": self.state["information_status"],
            "user_input_required": self.state["user_input_required"],
            "progress": len(self.state["workflow_history"]),
            "last_updated": datetime.now().isoformat()
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
workflow_controller = WorkflowController()


def check_information_completeness_v2(gap_analysis_output: str) -> Tuple[bool, Dict[str, Any]]:
    """
    æƒ…å ±ã®å®Œå…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®šã™ã‚‹é–¢æ•°
    
    Args:
        gap_analysis_output: æƒ…å ±ä¸è¶³æ¤œå‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›
        
    Returns:
        (æƒ…å ±ãŒååˆ†ã‹ã©ã†ã‹, è©³ç´°æƒ…å ±)
    """
    result = workflow_controller.analyze_information_gap(gap_analysis_output)
    return result["action"] == "continue_analysis", result


def generate_user_questions(original_request: str, gap_analysis: str) -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€ä¿¡ã™ã‚‹ç¢ºèªè³ªå•ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    
    Args:
        original_request: å…ƒã®åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        gap_analysis: æƒ…å ±ä¸è¶³åˆ†æçµæœ
        
    Returns:
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ç¢ºèªè³ªå•ãƒ†ã‚­ã‚¹ãƒˆ
    """
    _, analysis_result = check_information_completeness_v2(gap_analysis)
    
    return workflow_controller.generate_clarification_questions(
        original_request=original_request,
        missing_info=analysis_result.get("missing_info", []),
        ambiguous_points=analysis_result.get("ambiguous_points", [])
    )


def integrate_user_feedback(original_request: str, 
                          questions: str, 
                          user_response: str) -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’çµ±åˆã—ã¦å®Œæˆã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        original_request: å…ƒã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        questions: é€ä¿¡ã—ãŸè³ªå•
        user_response: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”
        
    Returns:
        çµ±åˆã•ã‚ŒãŸå®Œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    """
    return workflow_controller.process_user_response(
        original_request=original_request,
        clarification_questions=questions,
        user_response=user_response
    )